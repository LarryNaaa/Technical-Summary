# HTTP

[TOC]

## 1. HTTP 是什么？描述一下

HTTP 是超文本传输协议，也就是**H**yperText **T**ransfer **P**rotocol。

## 2. 能否详细解释「超文本传输协议」？

- **HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。**

## 3. 那「HTTP 是用于从互联网服务器传输超文本到本地浏览器的协议HTTP」 ，这种说法正确吗？

- 这种说法是**不正确**的。因为也可以是「服务器< -- >服务器」，所以采用**两点之间**的描述会更准确。

## 4. HTTP 常见的状态码，有哪些？

![HTTP_1](/Users/na/IdeaProjects/Technical summary/Image/HTTP_1.webp)

- *1xx* 

  `1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

- *2xx*

  `2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

  「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。

  「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。

  「**206 Partial Content**」是应用于 HTTP 分块下载或断电续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

- *3xx*

  `3xx` 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

  「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。

  「**302 Moved Temporarily**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

  301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

  「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。

- *4xx*

  `4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

  「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。

  「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。

  「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

- *5xx*

  `5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

  「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。

  「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。

  「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。

  「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。

## 5. http 常见字段有哪些？

- *Host*：客户端发送请求时，用来指定服务器的域名。有了 `Host` 字段，就可以将请求发往「同一台」服务器上的不同网站。
- *Content-Length 字段*：服务器在返回数据时，会有 `Content-Length` 字段，表明本次回应的数据长度。
- *Connection 字段*：`Connection` 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 `Connection` 首部字段的值为 `Keep-Alive`。一个可以复用的 TCP 连接就建立了，直到客户端或服务器主动关闭连接。但是，这不是标准字段。
- *Content-Type 字段*：`Content-Type` 字段用于服务器回应时，告诉客户端，本次数据是什么格式。客户端请求的时候，可以使用 `Accept` 字段声明自己可以接受哪些数据格式。
- *Content-Encoding 字段*：`Content-Encoding` 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。客户端在请求时，用 `Accept-Encoding` 字段说明自己可以接受哪些压缩方法。

## 6. 说一下 GET 和 POST 的区别？

- `Get` 方法的含义是请求**从服务器获取资源**，这个资源可以是静态的文本、页面、图片视频等。
- `POST` 方法则是相反操作，它向 `URI` 指定的资源提交数据，数据就放在报文的 body 里。

## 7. GET 和 POST 方法都是安全和幂等的吗？区别？

- 先说明下安全和幂等的概念：

  - 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。

  - 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。
- 那么很明显 **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。
- **POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。
- get 方法是不安全的，因为在发送请求的过程中，请求参数会拼在 URL 后面，从而导致容易被攻击者窃取，对信息造成破坏和伪造；而 post 方法是把参数放在请求体 body 中的，这对用户来说不可见。**然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。要想安全传输，就只有加密，也就是 HTTPS。**
- get 请求的 URL 有长度限制(**最大长度是 2048 个字符，url 长度限制是某些浏览器和服务器的限制，和 HTTP 协议没有关系**)，而 post 请求会把参数和值放在消息体中，对数据长度没有要求。
- get 请求会被浏览器主动 cache，而 post 不会，除非手动设置。
- get 请求在浏览器反复的 `回退/前进` 操作是无害的，而 post 操作会再次提交表单请求。
- get 请求在发送过程中会产生一个 TCP 数据包；post 在发送过程中会产生两个 TCP 数据包。对于 get 方式的请求，浏览器会把 请求行 和 请求头 一并发送出去，服务器响应 200（返回数据）；而对于 post，浏览器先发送 请求行 和 请求头，服务器响应 100 continue，浏览器再发送 请求体data，服务器响应 200 ok（返回数据）。**header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。**

## 8. 你知道的 HTTP（1.1） 的优点有哪些，怎么体现的？

### 8.1 优点

- HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**，降低了学习和使用的门槛。
- HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。同时 HTTP 由于是工作在应用层（ `OSI` 第七层），则它**下层可以随意变化**。HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚至把 TCPP 层换成了基于 UDP 的 QUIC。
- *应用广泛和跨平台*

### 8.2 缺点

- 无状态
  - 无状态的**好处**，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。
  - 无状态的**坏处**，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。解法方案有很多种，其中比较简单的方式用 **Cookie** 技术。`Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。
- *明文传输*
  - 明文意味着在传输过程中的信息，是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。
  - 在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取
- *不安全*
  - 通信使用明文（不加密），内容可能会被窃听。比如，**账号信息容易泄漏，那你号没了。**
  - 不验证通信方的身份，因此有可能遭遇伪装。比如，**访问假的淘宝、拼多多，那你钱没了。**
  - 无法证明报文的完整性，所以有可能已遭篡改。比如，**网页上植入垃圾广告，视觉污染，眼没了。**
  - HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

### 8.3 那你说下 HTTP/1.1 的性能如何？

- *长连接*
  - **长连接**的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。
  - 持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。
- *管道(pipeline)网络传输*
  - 即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**
  - 但是服务器还是按照**顺序**，先回应 A 请求，完成后再回应 B 请求。要是 前面的回应特别慢，后面就会有许多请求排队等着。这称为「队头堵塞」。
- *队头阻塞*
  - 因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」。

## 9. HTTP 与 HTTPS 有哪些区别？

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- HTTP 的端口号是 80，HTTPS 的端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

## 10. HTTPS 解决了 HTTP 的哪些问题？

- HTTP 由于是明文传输，所以安全上存在以下三个风险：
  - **窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。
  - **篡改风险**，比如强制入垃圾广告，视觉污染，用户眼容易瞎。
  - **冒充风险**，比如冒充淘宝网站，用户钱容易没。
- HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议。可以很好的解决了上述的风险：
  - **信息加密**：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。
  - **校验机制**：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。
  - **身份证书**：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。

![HTTP_2](/Users/na/IdeaProjects/Technical summary/Image/HTTP_2.webp)

## 11. HTTPS 是如何解决上面的三个风险的？

- 通过**混合加密**的方式可以保证信息的**机密性**，解决了窃听的风险。HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：

  - 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
  - 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

  采用「混合加密」的方式的原因：

  - **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
  - **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

- **摘要算法**用来实现**完整性**，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。

  - 客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的指纹和当前算出的指纹做比较，若指纹相同，说明数据是完整的。
  
- *数字证书*借助第三方权威机构 `CA` （数字证书认证机构），将**服务器公钥放在数字证书**（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

## 12. HTTPS  是如何建立连接的？其间交互了什么？

- 客户端发起 HTTPS 请求，服务端返回证书，客户端对证书进行验证，验证通过后本地生成用于改造对称加密算法的随机数。

- 通过证书中的公钥对随机数进行加密传输到服务端，服务端接收后通过私钥解密得到随机数，之后的数据交互通过对称加密算法进行加解密。

![](https://mmbiz.qpic.cn/mmbiz_png/MOwlO0INfQqrl2wsAt33gEXuTrpLTahWqL16Qsojrp6xicbOFfSVzIBRZGGPIW7s05USVLyfm9prnC7VoklRd1w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

## 13. TCP/IP和OSI网络模型

- TCP/IP网络模型

![HTTP_4](/Users/na/IdeaProjects/Technical summary/Image/HTTP_4.png)

- OSI 七层网络模型，它就是在五层协议之上加了**表示层和会话层**
  - 应用层的作用是为应用程序提供服务。为应用程序提供服务并规定应用程序中通讯相关的细节。常见的协议有 `HTTP`，`FTP`，`TELNET`、`SMTP`。
  - 表示层的作用是数据格式的转换，加密和解密。将应用处理的信息转换为适合网络传输的格式，或者将来自下一层的数据转换为上层能处理的格式。常见的协议有 `ASCII`、`SSL/TLS` 等。
  - 会话层作用是建立、维护、管理会话连接，负责建立和断开通信连接，以及数据的分割等数据传输相关的管理。常见的协议有 `ADSP`、`RPC` 等。
  - 传输层管理两个节点之间的数据传输，建立、维护、管理端到端连接。此层有两个具有代表性的协议： `TCP` 与 `UDP`。传输层有一个重要作用，就是指定通信端口。
  - 网络层负责ip寻址和路由选择，将数据传输到目标地址。目标地址可以使多个网络通过路由器连接而成的某一个地址。主要由 `IP`、`ICMP` 两个协议组成。
  - 链路层负责网络层和物理层面之间的通信传输。例如与1个以太网相连的两个节点间的通讯。常见的协议有 `HDLC`、`PPP`、`SLIP` 等。
  - 物理层负责比特流传输，0、1比特流（0、1序列）与电压高低、光的闪灭之间的互换。典型的协议有 `RS 232C`、`RS 449/422/423`、`V.24` 和 `X.21`、`X.21bis` 等。

![HTTP_5](/Users/na/IdeaProjects/Technical summary/Image/HTTP_5.png)

- **HTTPS**：HTTP + TLS/SSL 协议组合而成，而安全性的保证正是 TLS/SSL 所做的工作。

![HTTP_6](/Users/na/IdeaProjects/Technical summary/Image/HTTP_6.png)

## 14. 什么是无状态协议，HTTP 是无状态协议吗，怎么解决

- 浏览器每次向服务器发起请求的时候，不是通过一个连接，而是每次都建立一个新的连接。如果是一个连接的话，服务器进程中就能保持住这个连接并且在内存中记住一些信息状态。而每次请求结束后，连接就关闭，相关的内容就释放了，所以记不住任何状态，成为无状态连接。
- HTTP协议的无状态性是指服务器的协议层无需为不同的请求之间建立任何相关关系，它特指的是协议层的无状态性。

## 15. UDP 和 TCP 的区别

- TCP 和 UDP 都位于计算机网络模型中的运输层，它们负责传输应用层产生的数据。

### 15.1 UDP 是什么

- UDP 的全称是 `User Datagram Protocol`，用户数据报协议。它不需要所谓的`握手`操作，从而加快了通信速度，允许网络上的其他主机在接收方同意通信之前进行数据传输。数据报是与分组交换网络关联的传输单元。
- UDP 的特点主要有
  - UDP 能够支持容忍数据包丢失的带宽密集型应用程序
  - UDP 具有低延迟的特点
  - UDP 能够发送大量的数据包
  - UDP 能够允许 DNS 查找，DNS 是建立在 UDP 之上的应用层协议。

### 15.2 TCP 是什么

- TCP 的全称是`Transmission Control Protocol` ，传输控制协议。它能够帮助你确定计算机连接到 Internet 以及它们之间的数据传输。通过三次握手来建立 TCP 连接，三次握手就是用来启动和确认 TCP 连接的过程。一旦连接建立后，就可以发送数据了，当数据传输完成后，会通过关闭虚拟电路来断开连接。
- TCP 的主要特点有
  - TCP 能够确保连接的建立和数据包的发送
  - TCP 支持错误重传机制
  - TCP 支持拥塞控制，能够在网络拥堵的情况下延迟发送
  - TCP 能够提供错误校验和，甄别有害的数据包。

### 15.3 TCP 和 UDP 的不同

首先概括一下基本的区别:

**TCP是一个面向连接的、可靠的、基于字节流的传输层协议。**

而**UDP是一个面向无连接的传输层协议。**(就这么简单，其它TCP的特性也就没有了)。

具体来分析，和 `UDP` 相比，`TCP` 有三大核心特性:

1. **面向连接**。所谓的连接，指的是客户端和服务器的连接，在双方互相通信之前，TCP 需要三次握手建立连接，而 UDP 没有相应建立连接的过程。
2. **可靠性**。TCP 花了非常多的功夫保证连接的可靠，这个可靠性体现在哪些方面呢？一个是有状态，另一个是可控制。

TCP 会精准记录哪些数据发送了，哪些数据被对方接收了，哪些没有被接收到，而且保证数据包按序到达，不允许半点差错。这是**有状态**。

当意识到丢包了或者网络环境不佳，TCP 会根据具体情况调整自己的行为，控制自己的发送速度或者重发。这是**可控制**。

相应的，UDP 就是`无状态`, `不可控`的。

1. **面向字节流**。UDP 的数据传输是基于数据报的，这是因为仅仅只是继承了 IP 层的特性，而 TCP 为了维护状态，将一个个 IP 包变成了字节流。

![HTTP_8](/Users/na/IdeaProjects/Technical summary/Image/HTTP_8.png)

### 15.4 TCP 三次握手：TCP 的连接过程

![HTTP_9](/Users/na/IdeaProjects/Technical summary/Image/HTTP_9.png)

- SYN：它的全称是 `Synchronize Sequence Numbers`，同步序列编号。是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立 TCP 连接时，首先会发送的一个信号。客户端在接受到 SYN 消息时，就会在自己的段内生成一个随机值 X。
- SYN-ACK：服务器收到 SYN 后，打开客户端连接，发送一个 SYN-ACK 作为答复。确认号设置为比接收到的序列号多一个，即 X + 1，服务器为数据包选择的序列号是另一个随机数 Y。
- ACK：`Acknowledge character`, 确认字符，表示发来的数据已确认接收无误。最后，客户端将 ACK 发送给服务器。序列号被设置为所接收的确认值即 Y + 1。

![HTTP_10](/Users/na/IdeaProjects/Technical summary/Image/HTTP_10.webp)

#### 15.4.1 tcp 为什么要三次握手，两次不行吗

- 因为TCP是双工传输模式，不区分客户端和服务端，连接的建立是双向的过程。如果只有两次，无法做到双向连接的建立，从建立连接server回复的SYN和ACK合并成一次可以看出来，他也不需要4次。
- 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。
- **具体例子：**“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”

#### 15.4.2 序列号是随机的吗

- TCP在开始传输数据前，客户端和服务器需要随机生成自己的初始序列号。C假冒A，B接受后把ACK会直接发给A。由于A没有发送过seq=ISN _C的请求，当A收到ISN_C的ack后直接发送reset 给B，最终关闭了链接。
- **加入初始序列号不是随机的，而是可以推测的，那么C就可以拿到ISN_B，然后模拟一个ACK过去，B最终会建立链接，**C开始传递数据，这就会产生非常严重的安全问题，所以ISN随机是必须的。

### 15.5 TCP 四次挥手：TCP 的释放过程

- 首先，客户端应用程序决定要终止连接(这里服务端也可以选择断开连接)。这会使客户端将 FIN 发送到服务器，并进入 `FIN_WAIT_1` 状态。当客户端处于 FIN_WAIT_1 状态时，它会等待来自服务器的 ACK 响应。
- 然后第二步，当服务器收到 FIN 消息时，服务器会立刻向客户端发送 ACK 确认消息。
- 当客户端收到服务器发送的 ACK 响应后，客户端就进入 `FIN_WAIT_2` 状态，然后等待来自服务器的 `FIN` 消息
- 服务器发送 ACK 确认消息后，一段时间（可以进行关闭后）会发送 FIN 消息给客户端，告知客户端可以进行关闭。
- 当客户端收到从服务端发送的 FIN 消息时，客户端就会由 FIN_WAIT_2 状态变为 `TIME_WAIT` 状态。处于 TIME_WAIT 状态的客户端允许重新发送 ACK 到服务器为了防止信息丢失。客户端在 TIME_WAIT 状态下花费的时间取决于它的实现，在等待一段时间后，连接关闭，客户端上所有的资源（包括端口号和缓冲区数据）都被释放。

![HTTP_11](/Users/na/IdeaProjects/Technical summary/Image/HTTP_11.png)

#### 15.5.1 四次挥手中什么是 time_wait 状态 ？

- TCP 连接中，**主动关闭连接**的一方出现的状态；（收到 FIN 命令，进入 TIME_WAIT 状态，并返回 ACK 命令）
- 确保服务器是否已经收到了我们的 ACK 报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。
- 为了保证 `ACK 重发`和`丢弃延迟数据`，设置 `time_wait` 为 2 倍的 `MSL`（报文最大存活时间）
- 1 个 MSL 确保四次挥手中主动关闭方最后的 ACK 报文最终能达到对端
- 1 个 MSL 确保对端没有收到 ACK 重传的 FIN 报文可以到达
- **可靠的实现 TCP 全双工连接的终止**：为了保证客户端发送的最后一个ACK报文能够到达服务端。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的服务端收不到对已发送的FIN+ACK报文段的确认。服务端会超时重传这个FIN+ACK报文段，而客户端就能在2MSL时间内收到这个重传的FIN+ACK报文段。如果客户端在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后就立即释放连接，就无法收到服务端重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样，服务端就无法按照正常的步骤进入CLOSED状态。 
- **处理延迟到达的报文**：客户端在发送完ACK报文段后，再经过2MSL时间，就可以使本连接持续的时间所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求的报文段。假设客户端发送ACK刚刚过了一个MSL时间，而服务端在收到这个ACK**之前一瞬间刚好**启动超时重传FIN，所以要等这个FIN也消失，就是2MSL了。

#### 15.5.2  time_wait状态什么场景下过多，会造成什么问题？

- 在**高并发短连接**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上。
- **高并发可以让服务器在短时间范围内同时占用大量端口**，而端口有个0~65535的范围，并不是很多，刨除系统和其他服务要用的，剩下的就更少了。
-  在这个场景中，**短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接**。
-  在socket的TIME_WAIT状态结束之前，该socket所占用的本地端口号将一直无法释放。
- 在高并发（每秒几万qps）并且采用短连接方式进行交互的系统中运行一段时间后，系统中就会存在大量的time_wait状态，如果time_wait状态把系统所有可用端口都占完了且尚未被系统回收时，就会出现无法向服务端创建新的socket连接的情况。此时系统几乎停转，任何链接都不能建立。

#### 15.5.3  close_wait 状态?

- 服务器端接收到客户端发送的FIN并发送ACK后进入该状态，该状态下服务器端如果还有数据则继续发送，否则发送FIN进入LAST_ACK状态

#### 15.5.4  close_wait 状态什么场景下过多，会造成什么问题？

- CLOSE_WAIT 状态在服务器停留时间很短，如果你发现大量的 CLOSE_WAIT 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般有如下几种可能：
  1. **程序问题：如果代码层面忘记了 close 相应的 socket 连接**，那么自然不会发出 FIN 包，从而导致 CLOSE_WAIT 累积；或者代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。
  2. **响应太慢或者超时设置过小：如果连接双方不和谐，一方不耐烦直接 timeout，另一方却还在忙于耗时逻辑，就会导致 close 被延后**。响应太慢是首要问题，不过换个角度看，也可能是 timeout 设置过小。

#### 15.5.5 为什么是四次挥手而不是三次？

- 因为服务端在接收到`FIN`, 往往不会立即返回`FIN`, 必须等到服务端所有的报文都发送完毕了，才能发`FIN`。因此先发一个`ACK`表示已经收到客户端的`FIN`，延迟一段时间才发`FIN`。这就造成了四次挥手。
- 如果是三次挥手会有什么问题？等于说服务端将`ACK`和`FIN`的发送合并为一次挥手，这个时候长时间的延迟可能会导致客户端误以为`FIN`没有到达客户端，从而让客户端不断的重发`FIN`。

#### 15.5.6 Linux下显示网络状态

```bash
# netstat -a
```

## 16. 地址栏输入 URL 发生了什么

- 在地址栏中输入了 `URL`，而地址栏会根据用户输入，做出如下判断：
  - 输入的是非 `URL` 结构的字符串，则会用浏览器默认的搜索引擎搜索该字符串
  - 输入的是 `URL` 结构字符串，则会构建完整的 `URL` 结构，浏览器进程会将完整的 `URL` 通过进程间通信，即 `IPC`，发送给网络进程
- 在网络进程接收到 `URL` 后，并不是马上对指定 `URL` 进行请求。首先，我们需要进行 `DNS` 解析域名得到对应的 `IP`，然后通过 `ARP` 解析 `IP` 得到对应的 `MAC`（`Media Access Control Address`）地址。而 `DNS` 解析域名的过程分为以下几个步骤：
  - 询问浏览器 `DNS` 缓存
  - 询问本地操作系统 `DNS` 缓存（即查找本地 `host` 文件）
  - 询问 `ISP`（`Internet Service Provider`）互联网服务提供商（例如电信、移动）的 `DNS` 服务器
  - 询问根服务器，这个过程可以进行递归和迭代两种查找的方式，如果根域名服务器无法告知本地 DNS 服务器下一步需要访问哪个顶级域名服务器，就会使用递归查询；可以告知则使用迭代
- 建立 `TCP` 连接，即**三次握手过程**，利用 `TCP` 通道进行**数据传输**：
  - 服务端接收到数据包，并发送确认数据包已收到的消息到客户端，不断重复这个过程
  - 客户端在发送一个数据包后，未接收到服务端的确定消息，则重新发送该数据包，即 `TCP` 的重发机制
  - 当接收完所有的数据包后，接收端会按照 `TCP` 头中的需要进行排序，形成完整的数据
- 在数据传输的过程还可能会发生的重定向的情况，即当网络进程接收到状态码为 3xx 的响应报文，则会根据响应报文首部字段中的 Location 字段的值进行重新向，即会重新发起请求
- 用户输入网址后向服务器发送内容请求，服务器接收到请求后触发Controller（控制器），控制器从Model（模型）和视图（View）中获取各种数据信息进行处理，最后视图（View）将数据渲染为HTML使得页面完整的呈献给用户。

- 最后，断开 `TCP` 连接，即**四次握手过程**

## 17. Cookie Session Token jwt

### 17.1 Cookie

- 称之为**会话跟踪技术**，就是在一次会话中跟踪记录一些状态。cookie就可以在一次会话从开始到结束的整个过程，全程跟踪记录客户端的状态（例如：是否登录、购物车信息、是否已下载等）。
- **cookie 存储在客户端：** cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。
- **cookie 是不可跨域的：** 每个 cookie 都会绑定单一的域名，无法在别的域名下获取使用，**一级域名和二级域名之间是允许共享使用的**（**靠的是 domain）**。
- cookie是储存在浏览器中的一段字符串，它本身是没有任何危害的，不包含任何可执行的代码。
- 储存cookie是**浏览器的功能**，浏览器的安装目录下会有一个专门存放不同域名下的**cookie**的文件夹。
- 当网页发起**http请求**的时候，浏览器首先会检查是否有对应域名的**cookie**，如果有，就会自动添加到**request header**中，发送给服务器。
- cookie的存放有大小限制，不可以超过4kb, 每一个域名下的cookie数量最多是20个

#### 17.1.1 通讯流程

- 登录的时候，服务器会响应头会返回一个不同用户的一个标识符(**cookie**) 
- 登录完成后，**cookie**会被存放在浏览器的不同域名下的**cookie**的文件夹中
- 访问服务器时，**浏览器**会自动在请求头带上刚刚存放的cookie去请求服务器
- 服务器接收到对应的cookie后，返回不同用户的数据给浏览器

#### 17.1.2 cookie的参数

- **expires**和**maxAge**  cookie在什么时间段内有效，maxAge的使用更加的方便和普遍，因为`expires`的时间限制是格林威治时间，写起来不方便，`maxAge`是根据你的当前时间+ 设置的时间(毫秒)，更加的方便。
- **domain**和**path**  限制cookie能被那些网站访问
- **secure**  设置`cookie`只在确保安全的请求中才会发送(https等安全协议)
- **httpOnly**  设置cookie能否通过js来访问，拥有httpOnly的cookie只能被服务器访问，如果在服务器端对 Cookie 设置了HttpOnly 属性，那么js脚本就不能读取到cookie，但是浏览器还是能够正常使用cookie，客户端/浏览器不能访问，可以用来防止XSS脚本攻击。黑客虽然无法直接读取，但是黑客依然可以通过HTTP trace来获取服务器返回的Cookie内容。所以在服务器端你需要将trace禁用。

### 17.2 Session

- **session 是另一种记录服务器和客户端会话状态的机制**
- **session 是基于 cookie 实现的，session 存储在服务器端，sessionId 会被存储到客户端的cookie 中**
- **session 认证流程：**
  - 用户浏览器访问web网站，输入用户名密码
  - 服务器校验用户名密码通过之后，生成sessonid并把sessionid和用户信息映射起来保存在服务器
  - 服务器将生成的sessionid返回给用户浏览器，浏览器将sessionid存入cookie
  - 此后用户对该网站发起的其他请求都将带上cookie中保存的sessionid
  - 服务端把用户传过来的sessionid和保存在服务器的sessionid做对比，如果服务器中有该sessionid则代表身份验证成功
- 缺点：
  - 代码安全机制不完善，可能存在CSRF漏洞
  - 服务端需要保存sessionid与客户端传来的sessionid做对比，当服务器为集群多机的情况下，需要复制sessionid，在多台集群机器之间共享
  - 如果需要单点登入，则须将sessionid存入redis等外部存储保证每台机器每个系统都能访问到，如果外部存储服务宕机，则单点登入失效

### 17.3 cookie和session区别

- cookie数据存放在客户的浏览器上，session数据放在服务器上
- cookie不是很安全，别人可以分析存放在本地的cookie并进行cookie欺骗，考虑到安全应当使用session
- session会在一定时间内保存在服务器上，当访问增多，会比较占用你服务器的性能，考虑到减轻服务器性能方面，应当使用cookie
- 单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie
- 建议将登录信息等重要信息存放为session，其他信息如果需要保留，可以放在cookie中
- session保存在服务器，客户端不知道其中的信心；cookie保存在客户端，服务器能够知道其中的信息
- session中保存的是对象，cookie中保存的是字符串
- session不能区分路径，同一个用户在访问一个网站期间，所有的session在任何一个地方都可以访问到，而cookie中如果设置了路径参数，那么同一个网站中不同路径下的cookie互相是访问不到的

### 17.4 **Token**

- **访问资源接口（API）时所需要的资源凭证**
- **简单 token 的组成：** uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign（签名，token 的前几位以哈希算法压缩成的一定长度的十六进制字符串）
- **特点：**
  - **服务端无状态化、可扩展性好**
  - **支持移动端设备**
  - 安全
  - 支持跨程序调用
- **token 的身份验证流程**：
  - 客户端使用用户名跟密码请求登录
  - 服务端收到请求，去验证用户名与密码
  - 验证成功后，服务端会签发一个 token 并把这个 token 发送给客户端
  - 客户端收到 token 以后，会把它存储起来，比如放在 cookie 里或者 localStorage 里
  - 客户端每次向服务端请求资源的时候需要带着服务端签发的 token
  - 服务端收到请求，然后去验证客户端请求里面带着的 token ，如果验证成功，就向客户端返回请求的数据

- **每一次请求都需要携带 token，需要把 token 放到 HTTP 的 Header 里**
- 基于 token 的用户认证是一种服务端无状态的认证方式，服务端不用存放 token 数据。用解析 token 的计算时间换取 session 的存储空间，从而减轻服务器的压力，减少频繁的查询数据库
- token 完全由应用管理，所以它可以避开同源策略

### 17.6 JWT

[](https://www.jianshu.com/p/c69f08ca056d)

[](https://blog.csdn.net/hxpjava1/article/details/81005195)

[](https://juejin.cn/post/6844903986466652173)

#### 17.6.1 token的结构

- 是一个很长的字符串，中间用点（`.`）分隔成三个部分

- Header 部分是一个 JSON 对象，描述 JWT 的元数据：
  - 签名的算法（alg）：默认是 HMAC SHA256（写成 HS256）
  - 令牌（token）的类型（type）：JWT 令牌统一写为`JWT`。
- Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。
  - iss (issuer)：签发人
  - exp (expiration time)：过期时间
  - sub (subject)：主题
  - aud (audience)：受众
  - nbf (Not Before)：生效时间
  - iat (Issued At)：签发时间
  - jti (JWT ID)：编号
  - 私有字段
- Signature 部分是对前两部分的签名，防止数据篡改。
  
  - 首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。
  
  - 服务器端进行验证时，使用相同的签名算法再次对头部和负载生成signature，比较token携带的signature和生成的是否一致，如果一致则合法
  
  - ```javascript
    HMACSHA256(
      base64UrlEncode(header) + "." +
      base64UrlEncode(payload),
      secret)
    ```

#### 17.6.2 JWT 认证流程

- 用户访问网站，输入账号密码登入
- 服务器校验通过，生成JWT，不保存JWT，直接返回给客户端
- 客户端将JWT存入cookie或者localStorage
- 此后用户发起的请求，都将使用js从cookie或者localStorage读取JWT放在http请求的header中，发给服务端
- 服务端获取header中的JWT，用base64URL算法解码各部分内容，并在服务端用同样的秘钥和算法生成signature，与传过来的signature对比，验证JWT是否合法

#### 17.6.3 签名算法
- **HS256**

  - HS256 数字签名基于一种特殊的函数：加密哈希函数SHA-256。
  - **哈希函数属性**
    - **不可逆性**：函数是完全不可逆的，把Header和Payload作用于这个函数后，没有人可以从函数输出的信息中取回Header和Payload的原始值。
    - **可重复生成**：哈希函数是可重复生成信息的，也就是如果我们输入同样的Header和Payload信息，每次得到的结果是完全一样的。这就意味着，给定输入组合和哈希输出值，我们总是可以校验该输出值(比如签名signature)的正确性，因为我们可以重新计算(我们有输入值的情况下)。
    - **没有冲突**：如果我们提供不同的输入值，总是得到不同的唯一的输出值。这就意味着我们将哈希函数作用于某个Payload和Header之后，总是得到相同的结果，其它输入值组合不会得到和这一样的结果，因此，哈希函数的不同输出值就代表了输入值的不同。
    - **不可预测性**：哈希函数的最后一个属性就是不可预测性，给定一个输出值，无法通过各种手段猜测到输入值。假设我们尝试从上面的输出值中找到生成它的Payload，我们只能猜测输入值然后对比输出值看看是否匹配。
  - 缺点：
    - 如果输入的密码相对弱的话，HS256可能会被暴力破解，基于密钥的技术都有这个问题。
    - 在修改密码后，需要把它分发并安装到所有需要它的网络节点。这不仅不方便，而且容易出错，还涉及到服务器间的协调和暂停服务问题。如果服务器是由另外的团队维护，比如第三方组织，这种方式就更不可行了。
    - 创建和校验JWT的能力没有区分开，使用HS256时，网络的任何人都可以创建和校验token，因为他们都有密码。这就意味着密码可能会从更多的地方丢失或者受攻击，因为密码到处分发，而并不是每个应用都具有一样的安全保护机制。

- **RS256**([**RS256**](https://www.zhihu.com/search?type=content&q=hs256))

  - 使用RS256我们同样需要生成一个MAC，其目的仍然是创建一个数字签名来证明一个JWT的有效性。只是在这种签名方式中就，我们将创建token和校验token的能力分开，只有认证服务器具备创建的能力，而应用服务器，具备校验的能力。

  - 这样，我们需要创建两个密钥而不是一个：

    1. 仍然需要一个私钥，不过这次它只能被认证服务器拥有，只用来签名JWT。
    2. 私钥只能用来签名JWT，不能用来校验它。
    3. 第二个密钥叫做公钥(public key)，是应用服务器使用来校验JWT。
    4. 公钥可以用来校验JWT，但不能用来给JWT签名。
    5. 公钥一般不需要严密保管，因为即便黑客拿到了，也无法使用它来伪造签名。

  - RS256使用一种特殊的密钥，叫RSA密钥。RSA是一种加解密算法，使用一个密钥进行加密，然后用另外一个密钥解密。值得注意的是，RSA不是哈希函数，从定义上来说，这种方式加密是可逆的，也就是我们可以从加密后的内容得到原始内容。

  - 接收者将:

    1. 取出Header和Payload，然后使用SHA-256进行哈希。
    2. 使用公钥解密数字签名，得到签名的哈希值。
    3. 接收者将解密签名得到的哈希值和刚使用Header和Payload参与计算的哈希值进行比较。如果两个哈希值相等，则证明JWT确实是由认证服务器创建的。

    任何人都可以计算哈希值，但只有认证服务器可以使用RSA私钥对其进行加密。

#### 17.6.4 CSRF和XSS问题

- 使用JWT验证，由于服务端不保存用户信息，不用做sessonid复制，这样集群水平扩展就变得容易了。同时用户发请求给服务端时，前端使用JS将JWT放在header中手动发送给服务端，服务端验证header中的JWT字段，而非cookie信息，这样就避免了CSRF漏洞攻击。

#### 17.6.5 JTW优缺点

- 优点：
  - 服务端无需存储jwt令牌，通过特定的算法和密钥校验token
  - 同时取出Payload中携带的用户ID，减少不必要的数据库查询
  - 使用JWT验证，由于服务端不保存用户信息，不用做sessonid复制，这样集群水平扩展就变得容易了。
  - 用户发请求给服务端时，前端使用JS将JWT放在header中手动发送给服务端，服务端验证header中的JWT字段，而非cookie信息，这样就避免了CSRF漏洞攻击。
- Spring的拦截器HandlerInterceptor接口，在Controller方法执行之前拦截需要鉴权的请求，验证token是否合法，合法就放行，不合法则直接抛出异常拦截请求。验证逻辑放在一个统一的切面层完成，Spring的AOP正好满足这一需要。
- jwt泄露，导致用户信息泄露，以及操作权被使用
1. jwt不能涉及用户关键数据，如果涉及需要将jwt进行加密。
  2. 缩短jwt有效期
  3. 使用https
  4. 重要服务进行二次验证
- jwt存储在哪？客户端能否统一处理让所有请求带上这个令牌？

  - 存储在cookie中,自动实现统一处理。但没法解决跨域问题
  - 设在http-header中，如 Authorization: Bearer <token> 。所有的http请求包含表单、ajax、同步跳转都要加上这个header.
- jwt伪造，如果签名密钥泄露出去了那么jwt就可以被伪造

  - 签名密钥泄露并且被伪造token，这个在服务端是无法感知的。只能加强对secret的管理，并且对重要服务进行二次校验。
- 怎么强制将某个jwt失效？无法做到类似踢出某个用户的动作
  - 使用JWT的方式就是存在这种问题、无法解决。因为数据都不存储在服务端。一旦颁发token只有等待失效。

### 17.7 CSRF（Cross-Site Request Forgery，跨站点伪造请求）

- 在一个浏览器中打开了两个标签页，其中一个页面通过窃取另一个页面的 cookie 来发送伪造的请求，因为 cookie 是随着请求自动发送到服务端的。
- 一个**CSRF**攻击需要2个条件
  1. **登录了一个受信任的网站A，并且本地存放了cookie**
  2. **在不关闭A的情况下，访问了危险网站B**
- 1. 第一，登录受害者网站。如果受害者网站是基于 cookie 的用户验证机制，那么当用户登录成功后，浏览器就会保存一份服务端的 SESSIONID。
2. 第二，这时候在同一个浏览器打开攻击者网站，虽然说它无法获取 SESSIONID 是什么（因为设置了 http only 的 cookie 是无法被 JavaScript 获取的），但是从浏览器向受害者网站发出的任何请求中，都会携带它的 cookie，无论是从哪个网站发出。
  3. 第三，利用这个原理，在攻击者网站发出一个请求，命令受害者网站进行一些敏感操作。由于此时发出的请求是处于 session 中的，所以只要该用户有权限，那么任何请求都会被执行。

![HTTP_28](/Users/na/IdeaProjects/Technical summary/Image/HTTP_28.webp)

- 服务器端防御CSRF攻击主要有三种策略：验证HTTP Referer字段，请求参数中添加csrf token并验证，在HTTP头中自定义属性并验证。
  - 验证HTTP Referer字段：根据HTTP协议，在HTTP头中有一个字段叫Referer，它记录了HTTP请求的来源地址。服务器端设置拦截器，验证Referer，如果是合法地址则通过。**Referer 是浏览器设置的，在浏览器兼容性大不相同的时代中，如果存在某种浏览器允许用户修改这个值，那么 CSRF 漏洞依然存在。**
  - 请求参数中添加csrf token并验证：由于CSRF的本质在于攻击者欺骗用户去访问自己设置的地址，所以如果要求在访问敏感数据请求时，要求用户浏览器提供不保存在cookie中，并且攻击者无法伪造的数据作为校验，那么攻击者就无法再执行CSRF攻击。这种数据通常是表单中的一个数据项。服务器将其生成并附加在表单中，其内容是一个伪乱数。当客户端通过表单提交请求时，这个伪乱数也一并提交上去以供校验。正常的访问时，客户端浏览器能够正确得到并传回这个伪乱数，而通过CSRF传来的欺骗性攻击中，攻击者无从事先得知这个伪乱数的值，服务器端就会因为校验token的值为空或者错误，拒绝这个可疑请求。
  - 在请求头中自定义属性并验证：自定义属性的方法也是使用token并进行验证，和前一种方法不同的是，这里并不是把token以参数的形式置于HTTP请求体中，而是把它放到HTTP请求头中自定义的属性里。将token放入请求头中的Authoriaztion字段中。这样解决了前一种方法在请求中加入token的不便，同时，通过这个类请求的地址不会被记录到浏览器的地址栏，也不用担心token会通过Referer泄露到其他网站。

### 17.8 XSS(cross site scripting)跨网页脚本攻击

- 恶意攻击者往Web页面里插入恶意Script代码，当用户浏览该页之时，嵌入其中Web里面的Script代码会被执行，从而达到恶意攻击用户的目的。

- 无论是cookie-session还是JWT，都存在被XSS攻击盗取的风险

- 避免xss攻击，客户端和服务端都应该对提交数据进行xss攻击转义。

- XSS的攻击方式

  （1）反射型： 发出请求时，XSS代码出现在URL中，作为输入提交到服务器端，服务器端解析后响应，XSS随响应内容一起返回给浏览器，最后浏览器解析执行XSS代码，这个过程就像一次发射，所以叫反射型XSS。

  （2）存储型: 存储型XSS和反射型的XSS差别就在于，存储型的XSS提交的代码会存储在服务器端（数据库，内存，文件系统等），下次请求目标页面时不用再提交XSS代码。
  
- **XSS的防御措施**：**对输入(和URL参数)进行过滤，对输出进行编码**。

  - 也就是对提交的所有内容进行过滤，对url中的参数进行过滤，过滤掉会导致脚本执行的相关内容；然后对动态输出到页面的内容进行html编码，使脚本无法在浏览器中执行。**虽然对输入过滤可以被绕过，但是也还是会拦截很大一部分的XSS攻击**。

  - 输入(和URL参数)进行过滤：主要的思路就是**将容易导致XSS攻击的边角字符替换成全角字符**。< 和 > 是脚本执行和各种html标签需要的，比如 <script>，& 和 # 以及 % 在对URL编码试图绕过XSS filter时，会出现。我们说对输入的过滤分为白名单和黑名单。上面的XSS filter就是一种黑名单的过滤，黑名单就是列出不能出现的对象的清单，一旦出现就进行处理。还有一种白名单的过滤，白名单就是列出可被接受的内容，比如规定所有的输入只能是“大小写的26个英文字母和10个数字，还有-和_”，所有其他的输入都是非法的，会被抛弃掉。很显然如此严格的白名单是可以100%拦截所有的XSS攻击的。但是现实情况一般是不能进行如此严格的白名单过滤的。

  - 对于输入，处理使用XSS filter之外，对于每一个输入，在客户端和服务器端还要进行各种验证，验证是否合法字符，长度是否合法，格式是否正确。在客户端和服务端都要进行验证，因为客户端的验证很容易被绕过。其实这种验证也分为了黑名单和白名单。黑名单的验证就是不能出现某些字符，白名单的验证就是只能出现某些字符。尽量使用白名单。

  - 对输出进行编码：在输出数据之前对潜在的威胁的字符进行编码、转义是防御XSS攻击十分有效的措施。如果使用好的话，理论上是可以防御住所有的XSS攻击的。对所有要动态输出到页面的内容，通通进行相关的编码和转义。当然转义是按照其输出的上下文环境来决定如何转义的。

  - 作为body文本输出，作为html标签的属性输出，此时的转义规则如下：
  
    < 转成 &lt;
  
    \> 转成 &gt;
  
    & 转成 &amp;
  
    " 转成 &quot;
  
    ' 转成 &#39
  
  - javascript事件，除了上面的那些转义之外，还要附加上下面的转义：
  
    \ 转成 \\
  
    / 转成 \/
  
    ; 转成 ；(全角;)
  
  - URL属性，要确保这些url没有执行恶意连接。确保href 和 src 的值必须以 http://开头，白名单方式；不能有10进制和16进制编码字符。
  

### 17.9 Web Storage

- HTML5 提供了两种在客户端存储数据的新方法：localStorage和sessionStorage
- 优点：
  - CSRF免疫，因为不会被浏览器自动发送，后端并不需要花费时间精力来做CSRF相关的防护
  - 主要是用来作为本地存储来使用的，解决了cookie存储空间不足的问题(cookie中每条cookie的存储空间为4k)，localStorage中一般浏览器支持的是5M大小

#### 17.9.1 **localStorage**

- **localStorage**的生命周期是永久性的。localStorage存储的数据，即使关闭浏览器，也不会让数据消失，除非主动的去删除数据。

- 主要是用来作为本地存储来使用的，解决了cookie存储空间不足的问题(cookie中每条cookie的存储空间为4k)，localStorage中一般浏览器支持的是5M大小，这个在不同的浏览器中localStorage会有所不同。

- 局限：

  - 1、浏览器的大小不统一，并且在IE8以上的IE版本才支持localStorage这个属性

    2、目前所有的浏览器中都会把localStorage的值类型限定为string类型，这个在对我们日常比较常见的 JSON对象类型需要一些转换（JSON.parse（）//转为数组）（JSON.stringify() //转为字符串）

    3、localStorage在浏览器的隐私模式下面是不可读取的

    4、localStorage本质上是对字符串的读取，如果存储内容多的话会消耗内存空间，会导致页面变卡

    5、localStorage不能被爬虫抓取到

- localStorage与sessionStorage的唯一一点区别就是localStorage属于永久性存储，而sessionStorage属于当会话结束的时候，sessionStorage中的键值对会被清空

#### 17.9.2 **sessionStorage**

- **sessionStorage** 的生命周期是在浏览器关闭前。
- 特性：
  - 关闭浏览器sessionStorage 失效；
  - 页面刷新不会消除数据；
  - 只有在当前页面打开的链接，才可以访sessionStorage的数据，使用window.open打开页面和改变localtion.href方式都可以获 取到sessionStorage内部的数据;

#### 17.9.3 **localStorage，sessionStorage和cookie的区别**

- cookie数据始终在同源的http请求中携带（即使不需要），即cookie在浏览器和服务器间来回传递，而sessionStorage和localStorage不会自动把数据发送给服务器，仅在本地保存。cookie数据还有路径（path）的概念，可以限制cookie只属于某个路径下
- 存储大小限制也不同，cookie数据不能超过4K，同时因为每次http请求都会携带cookie、所以cookie只适合保存很小的数据，如会话标识。sessionStorage和localStorage虽然也有存储大小的限制，但比cookie大得多，可以达到5M或更大
- 数据有效期不同，sessionStorage：仅在当前浏览器窗口关闭之前有效；localStorage：始终有效，窗口或浏览器关闭也一直保存，因此用作持久数据；cookie：只在设置的cookie过期时间之前有效，即使窗口关闭或浏览器关闭
- 作用域不同，sessionStorage不在不同的浏览器窗口中共享，即使是同一个页面；localstorage在所有同源窗口中都是共享的；cookie也是在所有同源窗口中都是共享的
- web Storage支持事件通知机制，可以将数据更新的通知发送给监听者
- web Storage的api接口使用更方便

## 18. Http1.0 和HTTP1.1 和 Http2.x 的区别

### 18.1 说说 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

- HTTP/1.1 相比 HTTP/1.0 性能上的改进：
  - 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
  - 支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

## 18.2 那上面的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？

- HTTP/1.1 还是有性能瓶颈：

  - 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
  - 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
  - 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
  - 没有请求优先级控制；
  - 请求只能从客户端开始，服务器只能被动响应。

- *1. 头部压缩*

  HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的分**。

  这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

- *2. 二进制格式*

  HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式。**

  头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧和数据帧**。
  
  因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这**增加了数据传输的效率**。
  
- *3. 数据流*

  HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

  每个请求或回应的所有数据包，称为一个数据流（`Stream`）。

  每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

  客户端还可以**指定数据流的优先级**。优先级高的请求，服务器就先响应该请求。

- *4. 多路复用*

  HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**。

  移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟，大幅度提高了连接的利用率**。

  举例来说，在一个 TCP 连接里，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程非常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。

- *5. 服务器推送*

  HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。

  举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，**减少延时的等待**，也就是服务器推送（Server Push，也叫 Cache Push）。

## 18.3 HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？

- HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。

  所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。

  - HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了
  - HTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。

  这都是基于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

- UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。

  大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

  - QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，**其他流不会受到影响**。
  - TL3 升级成了最新的 `1.3` 版本，头部压缩算法也升级成了 `QPack`。
  - HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 `TLS/1.3` 的三次握手。QUIC 直接把以往的 TCP 和 `TLS/1.3` 的 6 次交互**合并成了 3 次，减少了交互次数**。

## 19. HTTP报文结构

### 19.1 HTTP请求报文

- 请求报文有4部分组成:
  - 请求行
  - 请求头
  - 空行
  - 请求体
  
- 请求行包括：请求方法、请求的URL的地址、HTTP协议版本。

- 请求头部: 报文头包含若干个属性，格式为“属性名:属性值”，服务端据此获取客户端的信息。
  
  - Client-IP：提供了运行客户端的机器的IP地址
  
    From：提供了客户端用户的E-mail地址
  
    **Host**：给出了接收请求的服务器的主机名和端口号
  
    Referer：提供了包含当前请求URI的文档的URL
  
    UA-Color：提供了与客户端显示器的显示颜色有关的信息
  
    UA-CPU：给出了客户端CPU的类型或制造商
  
    UA-OS：给出了运行在客户端机器上的操作系统名称及版本
  
    User-Agent：将发起请求的应用程序名称告知服务器
  
    **Accept**：告诉服务器能够发送哪些媒体类型
  
    Accept-Charset：告诉服务器能够发送哪些字符集
  
    Accept-Encoding：告诉服务器能够发送哪些编码方式
  
    Accept-Language：告诉服务器能够发送哪些语言
  
    TE：告诉服务器可以使用那些扩展传输编码
  
    Expect：允许客户端列出某请求所要求的服务器行为
  
    Range：如果服务器支持范围请求，就请求资源的指定范围
  
    **Cookie**：客户端用它向服务器传送数据
  
    Cookie2：用来说明请求端支持的cookie版本
  
- 请求体: post/put等请求携带的数据，键值对的形式

![HTTP_14](/Users/na/IdeaProjects/Technical summary/Image/HTTP_14.jpg)

### 19.2 HTTP响应报文

- 响应报文有4部分组成:
  - 响应行
  - 响应头
  - 空行
  - 响应体
- 响应行： 由协议版本，状态码和状态描述组成，例如`HTTP/1.1 200 OK`。
- 响应头：也是由多个属性组成
  - Age：(从最初创建开始)响应持续时间
  - Public：服务器为其资源支持的请求方法列表
  - Retry-After：如果资源不可用的话，在此日期或时间重试
  - Server：服务器应用程序软件的名称和版本
  - Title：对HTML文档来说，就是HTML文档的源端给出的标题
  - Warning：比原因短语更详细一些的警告报文
  - Accept-Ranges：对此资源来说，服务器可接受的范围类型
  - Vary：服务器会根据这些首部的内容挑选出最适合的资源版本发送给客户端
  - Proxy-Authenticate：来自代理的对客户端的质询列表
  - **Set-Cookie**：在客户端设置数据，以便服务器对客户端进行标识
  - Set-Cookie2：与Set-Cookie类似
  - WWW-Authenticate：来自服务器的对客户端的质询列表
- 响应体：服务器响应的数据

![HTTP_15](/Users/na/IdeaProjects/Technical summary/Image/HTTP_15.jpg)

### 19.3 实体标头

- 实体标头是描述消息正文内容的 HTTP 标头。实体标头用于 HTTP 请求和响应中。头部`Content-Length`、 `Content-Language`、 `Content-Encoding` 是实体头。

  - Content-Length 实体报头指示实体主体的大小，以字节为单位，发送到接收方。
  - Content-Language 实体报头描述了客户端或者服务端能够接受的语言。
  - Content-Encoding 这又是一个比较麻烦的属性，这个实体报头用来压缩媒体类型。Content-Encoding 指示对实体应用了何种编码。常见的内容编码有这几种： **gzip、compress、deflate、identity** ，这个属性可以应用在请求报文和响应报文中

  ![HTTP_16](/Users/na/IdeaProjects/Technical summary/Image/HTTP_16.webp)

### 19.4 请求标头

![HTTP_17](/Users/na/IdeaProjects/Technical summary/Image/HTTP_17.png)

### 19.5 响应标头

![HTTP_18](/Users/na/IdeaProjects/Technical summary/Image/HTTP_18.webp)

## 20. 让我们了解在HTTP/1.1有多少中请求方法

```java
1.GET为获取资源数据
get方法用于请求指定的页面信息，并返回请求消息的主体

2.POST为提交资源数据
post方法用于向指定的资源提交数据

3.PUT为更新资源数据
4.DELETE为删除资源数据
5.HEAD为读取资源的元数据
6.OPTIONS为读取资源多支持的所有请求方法
7.TRACE为回显服务器收到额请求
8.CONNECT为保留将来使用
```

## 21. TCP拥塞控制

- 拥塞控制（congestion control)是TCP协议的一项重要功能，TCP的拥塞控制机制是从端到端的角度，推测网络是否发生拥塞，如果推断网络发生拥塞，则立即将数据发送速率降下来，以便缓解网络拥塞。 

- TCP的拥塞控制采用的是窗口机制，通过调节窗口的大小实现对数据发送速率的调整。

- 发送端判断网络发生拥塞的依据是：发送端设置一个重传计时器RTO，对于某个已发出的数据报文段，如果在RTO计时到期后，还没有收到来自接收端的确认，则认为此时网络发生了拥塞。也就是**发生了超时重传，就会认为网络出现了用拥塞。**

- TCP的拥塞控制[算法]()包括了慢启动（slow start）、拥塞避免（congestion avoidance）、快速重传（fast retransmit）和快速恢复（fast recovery）四部分。

- **拥塞窗口** `cwnd`是发送方维护的一个 的状态变量，它会根据**网络的拥塞程度动态变化的**。swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。拥塞窗口 `cwnd` 变化的规则：

  - 只要网络中没有出现拥塞，`cwnd` 就会增大；
  - 但网络中出现了拥塞，`cwnd` 就减少；

- 慢启动：TCP采用试探的方法，逐渐增大拥塞窗口cwnd。通常在刚开始发送数据报文段时，先将拥塞窗口cwnd设置为一个TCP最大段长度MSS的值(1500-20-20=1460)。而在每收到一个数据报文段的确认后，cwnd就增加一个MSS的数值。如果定义从发送端发出一个数据报文段到收到这个数据报文段的确认的时间间隔为往返时间RTT，则在慢启动阶段，每经过一个RTT，cwnd的值就加倍。

- 慢启动门限  `ssthresh` （slow start threshold），`ssthresh` 的大小是 `65535` 字节。

  - 当 `cwnd < ssthresh` 时，使用慢启动算法。
  - 当 `cwnd >= ssthresh` 时，就会使用「拥塞避免算法」。

- 拥塞避免算法：当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长。

- 当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，sshresh 和 cwnd 的值会发生变化：

  - `ssthresh` 设为 `cwnd/2`，
  - `cwnd` 重置为 `1`

- 快速重传：当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

  TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

  - `cwnd = cwnd/2` ，也就是设置为原来的一半;
  - `ssthresh = cwnd`;
  - 进入快速恢复算法

- 快速恢复：快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。

  - 快速恢复算法如下：
    - `cwnd = cwnd/2` ，也就是设置为原来的一半;
    - `ssthresh = cwnd`;
    - cwnd 线性增加，进入了拥塞避免算法

![HTTP_24](/Users/na/IdeaProjects/Technical summary/Image/HTTP_24.webp)

## 22. TCP实现可靠性传输

- TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。

- TCP 实现可靠传输的方式之一，是通过序列号与确认应答。在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。

- **校验和**：发送方在发送数据之前计算校验和，接收方收到数据后同样计算，如果不一致，那么传输有误。

  **确认应答，序列号**：TCP进行传输时数据都进行了编号，每次接收方返回ACK都有确认序列号。

  **超时重传**：如果发送方发送数据一段时间后没有收到ACK，那么就重发数据。

  **连接管理**：三次握手和四次挥手的过程。

  **流量控制**：TCP协议报头包含16位的窗口大小，接收方会在返回ACK时同时把自己的即时窗口填入，发送方就根据报文中窗口的大小控制发送速度。

  **拥塞控制**：刚开始发送数据的时候，拥塞窗口是1，以后每次收到ACK，则拥塞窗口+1，然后将拥塞窗口和收到的窗口取较小值作为实际发送的窗口，如果发生超时重传，拥塞窗口重置为1。这样做的目的就是为了保证传输过程的高效性和可靠性。

### 22.1 **重传机制**

- 常见的重传机制：
  - 超时重传
  - 快速重传
  - SACK
  - D-SACK
  
- 超时重传
  
  - 重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据
  - TCP 会在以下两种情况发生超时重传：
    - 数据包丢失
    - 确认应答丢失
  
  ![HTTP_19](/Users/na/IdeaProjects/Technical summary/Image/HTTP_19.webp)

  - `RTT`（Round-Trip Time 往返时延）：就是**数据从网络一端传送到另一端所需的时间**，也就是包的往返时间。
  
  - 超时重传时间是以 `RTO` （Retransmission Timeout 超时重传时间）表示。
  
    ![HTTP_20](/Users/na/IdeaProjects/Technical summary/Image/HTTP_20.webp)
  
  - 上图中有两种超时时间不同的情况：
  
    - 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；
    - 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。
  
  - 根据上述的两种情况，我们可以得知，**超时重传时间 RTO 的值应该略大于报文往返  RTT 的值**。
  
  - 估计往返时间，通常需要采样以下两个：
  
    - 需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。
    - 除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。
  
  - 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**
  
- **快速重传（Fast Retransmit）**

  - **不以时间为驱动，而是以数据驱动重传**。
  
  - 快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
  
    ![HTTP_21](/Users/na/IdeaProjects/Technical summary/Image/HTTP_21.png)
  
  - 在上图，发送方发出了 1，2，3，4，5 份数据：
  
    - 第一份 Seq1 先送到了，于是就 Ack 回 2；
    - 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
    - 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
    - **发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。**
    - 最后，接收到收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。
  
  - 快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是**重传的时候，是重传之前的一个，还是重传所有的问题。**
  
- `SACK`（ Selective Acknowledgment 选择性确认）

  - 这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。
  
  - 如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。
  
    ![HTTP_22](/Users/na/IdeaProjects/Technical summary/Image/HTTP_22.webp)
  
- Duplicate SACK

  -  又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**
  
    ![HTTP_22](/Users/na/IdeaProjects/Technical summary/Image/HTTP_22.png)
  
  - ACK丢包：
  
    - 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
    - **于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500**，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 `D-SACK`。
    - 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。
    
    ![HTTP_23](/Users/na/IdeaProjects/Technical summary/Image/HTTP_23.png)
    
  -  网络延迟：
  
    -   数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
    -   而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
    -   **所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。**
    -   这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。
    
  -  可见，`D-SACK` 有这么几个好处：
  
     1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
     2. 可以知道是不是「发送方」的数据包被网络延迟了;
     3. 可以知道网络中是不是把「发送方」的数据包给复制了;

### 22.2 滑动窗口

- 对于发送端和接收端而言，TCP 需要把发送的数据放到**发送缓存区**, 将接收的数据放到**接收缓存区**。而流量控制索要做的事情，就是在通过接收缓存区的大小，控制发送端的发送。如果对方的接收缓存区满了，就不能再继续发送了。

- **发送方根据收到ACK当中的期望收到的下一个字节的序号n以及窗口m，还有当前已经发送的字节序号x，算出还可以发送的字节数。** **假定当前发送方已发送到第x字节，则可以发送的字节数就是y=m-(x-n)**


#### 22.2.1 窗口大小由哪一方决定？

- TCP 头里有一个字段叫 `Window`，也就是窗口大小。**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

- 所以，通常窗口的大小是由接收方的决定的。发送方发送的数据大小不能超过接收方的窗口大小，否则接收方就无法正常接收到数据。

#### 22.2.2 发送方的滑动窗口

![](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhgesUOXicVCTx6j4WPOa8heRQc3aPPwWDAIMnUJocXjmABL8JSjnkyenw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 发送方的窗口，上图就是发送方缓存的数据，根据处理的情况分成四个部分，其中深蓝色方框是发送窗口，紫色方框是可用窗口
  - \#1 是已发送并收到 ACK确认的数据：1~31 字节
  - \#2 是已发送但未收到 ACK确认的数据：32~45 字节
  - \#3 是未发送但总大小在接收方处理范围内（接收方还有空间）：46~51字节
  - \#4 是未发送但总大小超过接收方处理范围（接收方没有空间）：52字节以后
- 当发送方把数据「全部」都一下发送出去后，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。

![](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhg3ZL5YZicgaInXFFlibY8KD1ibMaqndGybEBEwHCMYlzibX6aupGA11OI1A/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

- 当收到之前发送的数据 `32~36` 字节的 ACK 确认应答后，如果发送窗口的大小没有变化，则**滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认**，接下来 `52~56` 字节又变成了可用窗口，那么后续也就可以发送 `52~56` 这 5 个字节的数据了。

![](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhg64rlHPQwlXs1DCnT0zapq7hbeziazJ7mQ4ZFCtwRIwkg4gfFaxDoudg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 22.2.3 程序是如何表示发送方的四个部分的呢？

- TCP 滑动窗口方案使用三个指针来跟踪在四个传输类别中的每一个类别中的字节。其中两个指针是绝对指针（指特定的序列号），一个是相对指针（需要做偏移）。
- `SND.WND`：表示发送窗口的大小（大小是由接收方指定的）；
- `SND.UNA`：是一个绝对指针，它指向的是已发送但未收到确认的第一个字节的序列号，也就是 #2 的第一个字节。
- `SND.NXT`：也是一个绝对指针，它指向未发送但可发送范围的第一个字节的序列号，也就是 #3 的第一个字节。
- 指向 #4 的第一个字节是个相对指针，它需要 `SND.UNA` 指针加上 `SND.WND` 大小的偏移量，就可以指向 #4 的第一个字节了。
- 那么可用窗口大小的计算就可以是：**可用窗口 = SND.WND -（SND.NXT - SND.UNA）**

![](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhge0ujfyrkBBMicd4U4qiaubDemmA9BhjDalRicd1cxrAkBQqlBQSL1oGzg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

#### 22.2.4 接收方的滑动窗口

- 接下来我们看看接收方的窗口，接收窗口相对简单一些，根据处理的情况划分成三个部分：
  - \#1 + #2 是已成功接收并确认的数据（等待应用进程读取）；
  - \#3 是未收到数据但可以接收的数据；
  - \#4 未收到数据并不可以接收的数据；

![](https://mmbiz.qpic.cn/mmbiz_png/J0g14CUwaZeuicRMlA8rKvl5AVLibhibDhglnibEWRdZcD4QWuC61y9iaRoKlWUWyicnP0iaS01fAjsdGgKJnYJcfm0wA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)

其中三个接收部分，使用两个指针进行划分:

- `RCV.WND`：表示接收窗口的大小，它会通告给发送方。
- `RCV.NXT`：是一个指针，它指向期望从发送方发送来的下一个数据字节的序列号，也就是 #3 的第一个字节。
- 指向 #4 的第一个字节是个相对指针，它需要 `RCV.NXT` 指针加上 `RCV.WND` 大小的偏移量，就可以指向 #4 的第一个字节了。

#### 22.2.5 接收窗口和发送窗口的大小是相等的吗？

- 并不是完全相等，接收窗口的大小是**约等于**发送窗口的大小的。
- 因为滑动窗口并不是一成不变的。比如，当接收方的应用进程读取数据的速度非常快的话，这样的话接收窗口可以很快的就空缺出来。那么新的接收窗口大小，是通过 TCP 报文中的 Windows 字段来告诉发送方。那么这个传输过程是存在时延的，所以接收窗口和发送窗口是约等于的关系。

### 22.3 流量控制

- 什么是流量控制？流量控制的目的？
  - 如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制根本目的是防止分组丢失，它是构成TCP可靠性的一方面。
- 如何实现流量控制？
  - 由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议既保证了分组无差错、有序接收，也实现了流量控制。主要的方式就是接收方返回的 ACK 中会包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。
- 流量控制引发的死锁？怎么避免死锁的发生？
  - 当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。
  - 为了避免流量控制引发的死锁，TCP使用了持续计时器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。

## 23. TCP每个数据包大小怎么决定的，怎么计算的

- 以太网数据包（packet）的大小是固定的，最初是1518字节，后来增加到1522字节。其中， 1500 字节是负载（payload），22字节是头信息（head）。
- IP 数据包在以太网数据包里面，TCP 数据包在 IP 数据包里面。

![HTTP_26](/Users/na/IdeaProjects/Technical summary/Image/HTTP_26.png)

- TCP 包的大小就应该是 1522 - 以太网头(22) - IP头(20) - TCP头(20) = 1460 (BYTES)
- UDP 包的大小就应该是1522 - 以太网头(22) - IP头(20) - UDP头(8) = 1472(BYTES)

## 24. HTTP 连接建立过程

- 第1步：TCP通过三次握手建立双方连接；
- 第2步：客户端通过发送请求报文及请求数据给服务端；
- 第3步：服务端返回响应报文及响应数据给客户端；
- 第4步：TCP通过四次挥手进行断开连接。

![HTTP_25](/Users/na/IdeaProjects/Technical summary/Image/HTTP_25.png)

## 25. TCP如何保证传输的可靠性

1. 数据包校验
2. 对失序数据包重新排序（TCP报文具有序列号）
3. 丢弃重复数据
4. 应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；
5. 超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；
6. 流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出，**使用滑动窗口协议实现流量控制**。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在**返回ACK时将接受窗口大小放在TCP报文中的窗口字段**告知发送方。发送窗口的大小不能超过接受窗口的大小，**只有当发送方发送并收到确认之后，才能将发送窗口右移**。

## 26. 负载均衡

- **DNS**：这是最简单的负载均衡的方式，一般用于实现地理级别的负载均衡，不同地域的用户通过DNS的解析可以返回不同的IP地址，这种方式的负载均衡简单，但是扩展性太差，控制权在域名服务商。
- **Http重定向**：通过修改Http响应头的Location达到负载均衡的目的，Http的302重定向。这种方式对性能有影响，而且增加请求耗时。
- **反向代理**：作用于应用层的模式，也被称作为**七层负载均衡**，比如常见的Nginx，性能一般可以达到万级。这种方式部署简单，成本低，而且容易扩展。
- **IP**：作用于网络层的和传输层的模式，也被称作**四层负载均衡**，通过对数据包的IP地址和端口进行修改来达到负载均衡的效果。常见的有LVS（Linux Virtual Server），通常性能可以支持10万级并发。
- 按照类型来划分的话，还可以分成DNS负载均衡、硬件负载均衡、软件负载均衡。
- 其中硬件负载均衡价格昂贵，性能最好，能达到百万级，软件负载均衡包括Nginx、LVS这种。

## 27. BIO/NIO/AIO

- **BIO**：同步阻塞IO，每一个客户端连接，服务端都会对应一个处理线程，对于没有分配到处理线程的连接就会被阻塞或者拒绝。相当于是**一个连接一个线程**。数据的读取写入必须阻塞在一个线程内等待其完成。
- **NIO**：同步非阻塞IO，基于Reactor模型，客户端和channel进行通信，channel可以进行读写操作，通过多路复用器selector来轮询注册在其上的channel，而后再进行IO操作。这样的话，在进行IO操作的时候再用一个线程去处理就可以了，也就是**一个请求一个线程**。
- **AIO**：异步非阻塞IO，相比NIO更进一步，完全由操作系统来完成请求的处理，然后通知服务端开启线程去进行处理，因此是**一个有效请求一个线程**。

![](https://pic3.zhimg.com/80/v2-4240c9fd3182be3c5ef8af4f29948486_720w.jpg)

- **同步与异步的区别**

  - 同步

  发送一个请求，等待返回，再发送下一个请求，同步可以避免出现死锁，脏读的发生。

  - 异步

  发送一个请求，不等待返回，随时可以再发送下一个请求，可以提高效率，保证并发。

- **阻塞和非阻塞**

  - **阻塞**

  传统的IO流都是阻塞式的。也就是说，当一个线程调用read()或者write()方法时，该线程将被阻塞，直到有一些数据读读取或者被写入，在此期间，该线程不能执行其他任何任务。在完成网络通信进行IO操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量的客户端时，性能急剧下降。

  - **非阻塞**

  JavaNIO是非阻塞式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程会去执行其他任务。线程通常将非阻塞IO的空闲时间用于在其他通道上执行IO操作，所以单独的线程可以管理多个输入和输出通道。因此NIO可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端。

- NIO重点是把Channel（通道），Buffer（缓冲区），Selector（选择器）三个类之间的关系弄清楚。

  **1.缓冲区Buffer**

  Buffer是一个对象。它包含一些要写入或者读出的数据。在面向流的I/O中，可以将数据写入或者将数据直接读到Stream对象中。

  在NIO中，所有的数据都是用缓冲区处理。这也就本文上面谈到的IO是面向流的，NIO是面向缓冲区的。

  缓冲区实质是一个数组，通常它是一个字节数组（ByteBuffer），也可以使用其他类的数组。但是一个缓冲区不仅仅是一个数组，缓冲区提供了对数据的结构化访问以及维护读写位置（limit）等信息。

  最常用的缓冲区是ByteBuffer，一个ByteBuffer提供了一组功能于操作byte数组。除了ByteBuffer，还有其他的一些缓冲区，事实上，每一种Java基本类型（除了Boolean）都对应一种缓冲区，具体如下：

  - ByteBuffer：字节缓冲区
  - CharBuffer:字符缓冲区
  - ShortBuffer：短整型缓冲区
  - IntBuffer：整型缓冲区
  - LongBuffer:长整型缓冲区
  - FloatBuffer：浮点型缓冲区
  - DoubleBuffer：双精度浮点型缓冲区

  **2.通道Channel**

  Channel是一个通道，可以通过它读取和写入数据，他就像自来水管一样，网络数据通过Channel读取和写入。

  通道和流不同之处在于通道是双向的，流只是在一个方向移动，而且通道可以用于读，写或者同时用于读写。

  因为Channel是全双工的，所以它比流更好地映射底层操作系统的API，特别是在UNIX网络编程中，底层操作系统的通道都是全双工的，同时支持读和写。

  Channel有四种实现：

  - FileChannel:是从文件中读取数据。
  - DatagramChannel:从UDP网络中读取或者写入数据。
  - SocketChannel:从TCP网络中读取或者写入数据。
  - ServerSocketChannel:允许你监听来自TCP的连接，就像服务器一样。每一个连接都会有一个SocketChannel产生。

  **3.多路复用器Selector**

  Selector选择器可以监听多个Channel通道感兴趣的事情(read、write、accept(服务端接收)、connect，实现一个线程管理多个Channel，节省线程切换上下文的资源消耗。Selector只能管理非阻塞的通道，FileChannel是阻塞的，无法管理。

  **关键对象**

  - Selector：选择器对象，通道注册、通道监听对象和Selector相关。
  - SelectorKey：通道监听关键字，通过它来监听通道状态。

  **监听注册**

  监听注册在Selector

  > socketChannel.register(selector, SelectionKey.OP_READ);

  **监听的事件有**

  - OP_ACCEPT: 接收就绪，serviceSocketChannel使用的
  - OP_READ: 读取就绪，socketChannel使用
  - OP_WRITE: 写入就绪，socketChannel使用
  - OP_CONNECT: 连接就绪，socketChannel使用