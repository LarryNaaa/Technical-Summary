# HTTP

[TOC]

## 1. HTTP 是什么？描述一下

HTTP 是超文本传输协议，也就是**H**yperText **T**ransfer **P**rotocol。

## 2. 能否详细解释「超文本传输协议」？

- **HTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。**

## 3. 那「HTTP 是用于从互联网服务器传输超文本到本地浏览器的协议HTTP」 ，这种说法正确吗？

- 这种说法是**不正确**的。因为也可以是「服务器< -- >服务器」，所以采用**两点之间**的描述会更准确。

## 4. HTTP 常见的状态码，有哪些？

![HTTP_1](/Users/na/IdeaProjects/Technical summary/Image/HTTP_1.webp)

- *1xx* 

  `1xx` 类状态码属于**提示信息**，是协议处理中的一种中间状态，实际用到的比较少。

- *2xx*

  `2xx` 类状态码表示服务器**成功**处理了客户端的请求，也是我们最愿意看到的状态。

  「**200 OK**」是最常见的成功状态码，表示一切正常。如果是非 `HEAD` 请求，服务器返回的响应头都会有 body 数据。

  「**204 No Content**」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。

  「**206 Partial Content**」是应用于 HTTP 分块下载或断电续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。

- *3xx*

  `3xx` 类状态码表示客户端请求的资源发送了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是**重定向**。

  「**301 Moved Permanently**」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。

  「**302 Moved Temporarily**」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。

  301 和 302 都会在响应头里使用字段 `Location`，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。

  「**304 Not Modified**」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，用于缓存控制。

- *4xx*

  `4xx` 类状态码表示客户端发送的**报文有误**，服务器无法处理，也就是错误码的含义。

  「**400 Bad Request**」表示客户端请求的报文有错误，但只是个笼统的错误。

  「**403 Forbidden**」表示服务器禁止访问资源，并不是客户端的请求出错。

  「**404 Not Found**」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。

- *5xx*

  `5xx` 类状态码表示客户端请求报文正确，但是**服务器处理时内部发生了错误**，属于服务器端的错误码。

  「**500 Internal Server Error**」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。

  「**501 Not Implemented**」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。

  「**502 Bad Gateway**」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。

  「**503 Service Unavailable**」表示服务器当前很忙，暂时无法响应服务器，类似“网络服务正忙，请稍后重试”的意思。

## 5. http 常见字段有哪些？

- *Host*：客户端发送请求时，用来指定服务器的域名。有了 `Host` 字段，就可以将请求发往「同一台」服务器上的不同网站。
- *Content-Length 字段*：服务器在返回数据时，会有 `Content-Length` 字段，表明本次回应的数据长度。
- *Connection 字段*：`Connection` 字段最常用于客户端要求服务器使用 TCP 持久连接，以便其他请求复用。HTTP/1.1 版本的默认连接都是持久连接，但为了兼容老版本的 HTTP，需要指定 `Connection` 首部字段的值为 `Keep-Alive`。一个可以复用的 TCP 连接就建立了，直到客户端或服务器主动关闭连接。但是，这不是标准字段。
- *Content-Type 字段*：`Content-Type` 字段用于服务器回应时，告诉客户端，本次数据是什么格式。客户端请求的时候，可以使用 `Accept` 字段声明自己可以接受哪些数据格式。
- *Content-Encoding 字段*：`Content-Encoding` 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式。客户端在请求时，用 `Accept-Encoding` 字段说明自己可以接受哪些压缩方法。

## 6. 说一下 GET 和 POST 的区别？

- `Get` 方法的含义是请求**从服务器获取资源**，这个资源可以是静态的文本、页面、图片视频等。
- `POST` 方法则是相反操作，它向 `URI` 指定的资源提交数据，数据就放在报文的 body 里。

## 7. GET 和 POST 方法都是安全和幂等的吗？区别？

- 先说明下安全和幂等的概念：

  - 在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。

  - 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。
- 那么很明显 **GET 方法就是安全且幂等的**，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。
- **POST** 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是**不安全**的，且多次提交数据就会创建多个资源，所以**不是幂等**的。
- get 方法是不安全的，因为在发送请求的过程中，请求参数会拼在 URL 后面，从而导致容易被攻击者窃取，对信息造成破坏和伪造；而 post 方法是把参数放在请求体 body 中的，这对用户来说不可见。**然而，从传输的角度来说，他们都是不安全的，因为 HTTP 在网络上是明文传输的，只要在网络节点上捉包，就能完整地获取数据报文。要想安全传输，就只有加密，也就是 HTTPS。**
- get 请求的 URL 有长度限制(**最大长度是 2048 个字符，url 长度限制是某些浏览器和服务器的限制，和 HTTP 协议没有关系**)，而 post 请求会把参数和值放在消息体中，对数据长度没有要求。
- get 请求会被浏览器主动 cache，而 post 不会，除非手动设置。
- get 请求在浏览器反复的 `回退/前进` 操作是无害的，而 post 操作会再次提交表单请求。
- get 请求在发送过程中会产生一个 TCP 数据包；post 在发送过程中会产生两个 TCP 数据包。对于 get 方式的请求，浏览器会把 请求行 和 请求头 一并发送出去，服务器响应 200（返回数据）；而对于 post，浏览器先发送 请求行 和 请求头，服务器响应 100 continue，浏览器再发送 请求体data，服务器响应 200 ok（返回数据）。**header 和 body 分开发送是部分浏览器或框架的请求方法，不属于 post 必然行为。**

## 8. 你知道的 HTTP（1.1） 的优点有哪些，怎么体现的？

### 8.1 优点

- HTTP 基本的报文格式就是 `header + body`，头部信息也是 `key-value` 简单文本的形式，**易于理解**，降低了学习和使用的门槛。
- HTTP协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员**自定义和扩充**。同时 HTTP 由于是工作在应用层（ `OSI` 第七层），则它**下层可以随意变化**。HTTPS 也就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层，HTTP/3 甚至把 TCPP 层换成了基于 UDP 的 QUIC。
- *应用广泛和跨平台*

### 8.2 缺点

- 无状态
  - 无状态的**好处**，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。
  - 无状态的**坏处**，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。解法方案有很多种，其中比较简单的方式用 **Cookie** 技术。`Cookie` 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。
- *明文传输*
  - 明文意味着在传输过程中的信息，是可方便阅读的，通过浏览器的 F12 控制台或 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。
  - 在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取
- *不安全*
  - 通信使用明文（不加密），内容可能会被窃听。比如，**账号信息容易泄漏，那你号没了。**
  - 不验证通信方的身份，因此有可能遭遇伪装。比如，**访问假的淘宝、拼多多，那你钱没了。**
  - 无法证明报文的完整性，所以有可能已遭篡改。比如，**网页上植入垃圾广告，视觉污染，眼没了。**
  - HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。

### 8.3 那你说下 HTTP/1.1 的性能如何？

- *长连接*
  - **长连接**的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。
  - 持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。
- *管道(pipeline)网络传输*
  - 即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以**减少整体的响应时间。**
  - 但是服务器还是按照**顺序**，先回应 A 请求，完成后再回应 B 请求。要是 前面的回应特别慢，后面就会有许多请求排队等着。这称为「队头堵塞」。
- *队头阻塞*
  - 因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「**队头阻塞**」。

## 9. HTTP 与 HTTPS 有哪些区别？

- HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。
- HTTP 连接建立相对简单， TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。
- HTTP 的端口号是 80，HTTPS 的端口号是 443。
- HTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。

## 10. HTTPS 解决了 HTTP 的哪些问题？

- HTTP 由于是明文传输，所以安全上存在以下三个风险：
  - **窃听风险**，比如通信链路上可以获取通信内容，用户号容易没。
  - **篡改风险**，比如强制入垃圾广告，视觉污染，用户眼容易瞎。
  - **冒充风险**，比如冒充淘宝网站，用户钱容易没。
- HTTP**S** 在 HTTP 与 TCP 层之间加入了 `SSL/TLS` 协议。可以很好的解决了上述的风险：
  - **信息加密**：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。
  - **校验机制**：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。
  - **身份证书**：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。

![HTTP_2](/Users/na/IdeaProjects/Technical summary/Image/HTTP_2.webp)

## 11. HTTPS 是如何解决上面的三个风险的？

- 通过**混合加密**的方式可以保证信息的**机密性**，解决了窃听的风险。HTTPS 采用的是**对称加密**和**非对称加密**结合的「混合加密」方式：

  - 在通信建立前采用**非对称加密**的方式交换「会话秘钥」，后续就不再使用非对称加密。
  - 在通信过程中全部使用**对称加密**的「会话秘钥」的方式加密明文数据。

  采用「混合加密」的方式的原因：

  - **对称加密**只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。
  - **非对称加密**使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。

- **摘要算法**用来实现**完整性**，能够为数据生成独一无二的「指纹」，用于校验数据的完整性，解决了篡改的风险。

  - 客户端在发送明文之前会通过摘要算法算出明文的「指纹」，发送的时候把「指纹 + 明文」一同加密成密文后，发送给服务器，服务器解密后，用相同的摘要算法算出发送过来的明文，通过比较客户端携带的指纹和当前算出的指纹做比较，若指纹相同，说明数据是完整的。
  
- *数字证书*借助第三方权威机构 `CA` （数字证书认证机构），将**服务器公钥放在数字证书**（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。

## 12. HTTPS  是如何建立连接的？其间交互了什么？

- SSL/TLS 协议基本流程：

  - 客户端向服务器索要并验证服务器的公钥。
  - 双方协商生产「会话秘钥」。
  - 双方采用「会话秘钥」进行加密通信。

  前两步也就是 SSL/TLS 的建立过程，也就是握手阶段。

  SSL/TLS 的「握手阶段」涉及**四次**通信，可见下图：

  ![HTTP_12](/Users/na/IdeaProjects/Technical summary/Image/HTTP_12.webp)

- 第一步，客户端给出协议版本号、一个客户端生成的随机数（Client random），以及客户端支持的加密方法。

  第二步，服务器确认双方使用的加密方法和协议版本，并给出数字证书、以及一个服务器生成的随机数（Server random）。

  第三步，客户端通过CA确认数字证书有效，然后生成一个新的随机数（Premaster secret），并使用数字证书中的公钥，加密这个随机数，发给服务器。

  第四步，服务器使用自己的私钥，获取客户端发来的随机数（即Premaster secret）。

  第五步，客户端和服务器根据约定的加密方法，使用前面的三个随机数，生成"对话密钥"（session key），用来加密接下来的整个对话过程。

  1. 服务端有非对称加密的公钥A1，私钥A2；
  2. 客户端发起请求，服务端将公钥A1返回给客户端；
  3. 客户端随机生成一个对称加密的密钥K，用公钥A1加密后发送给服务端；
  4. 服务端收到密文后用自己的私钥A2解密，得到对称密钥K，此时完成了安全的对称密钥交换，解决了对称加密时密钥传输被人窃取的问题
  5. 之后双方通信都使用密钥K进行对称加解密。

- ## 13. TCP/IP 网络模型

  ![HTTP_4](/Users/na/IdeaProjects/Technical summary/Image/HTTP_4.png)

- OSI 七层网络模型，它就是在五层协议之上加了**表示层和会话层**

![HTTP_5](/Users/na/IdeaProjects/Technical summary/Image/HTTP_5.png)

- **HTTPS**：HTTP + TLS/SSL 协议组合而成，而安全性的保证正是 TLS/SSL 所做的工作。

![HTTP_6](/Users/na/IdeaProjects/Technical summary/Image/HTTP_6.png)

## 14. 什么是无状态协议，HTTP 是无状态协议吗，怎么解决

- `无状态协议(Stateless Protocol)` 就是指**浏览器对于事务的处理没有记忆能力**。
- HTTP 就是一种无状态的协议，他对用户的操作没有记忆能力。
- 当你向服务端发送请求时，服务端会给你发送一个认证信息，服务器第一次接收到请求时，开辟了一块 Session 空间（创建了Session对象），同时生成一个 sessionId ，并通过响应头的 Set-Cookie：JSESSIONID=XXXXXXX 命令，向客户端发送要求设置 Cookie 的响应；客户端收到响应后，在本机客户端设置了一个 JSESSIONID=XXXXXXX 的 Cookie 信息，该 Cookie 的过期时间为浏览器会话结束；

![HTTP_7](/Users/na/IdeaProjects/Technical summary/Image/HTTP_7.png)

- 接下来客户端每次向同一个网站发送请求时，请求头都会带上该 Cookie信息（包含 sessionId ）， 然后，服务器通过读取请求头中的 Cookie 信息，获取名称为 JSESSIONID 的值，得到此次请求的 sessionId。这样，你的浏览器才具有了记忆能力。
- 还有一种方式是使用 JWT 机制，它也是能够让你的浏览器具有记忆能力的一种机制。与 Cookie 不同，JWT 是保存在客户端的信息，它广泛的应用于单点登录的情况。JWT 具有两个特点
  - JWT 的 Cookie 信息存储在`客户端`，而不是服务端内存中。也就是说，JWT 直接本地进行验证就可以，验证完毕后，这个 Token 就会在 Session 中随请求一起发送到服务器，通过这种方式，可以节省服务器资源，并且 token 可以进行多次验证。
  - JWT 支持跨域认证，Cookies 只能用在`单个节点的域`或者它的`子域`中有效。如果它们尝试通过第三个节点访问，就会被禁止。使用 JWT 可以解决这个问题，使用 JWT 能够通过`多个节点`进行用户认证，也就是我们常说的`跨域认证`。

## 15. UDP 和 TCP 的区别

- TCP 和 UDP 都位于计算机网络模型中的运输层，它们负责传输应用层产生的数据。

### 15.1 UDP 是什么

- UDP 的全称是 `User Datagram Protocol`，用户数据报协议。它不需要所谓的`握手`操作，从而加快了通信速度，允许网络上的其他主机在接收方同意通信之前进行数据传输。数据报是与分组交换网络关联的传输单元。
- UDP 的特点主要有
  - UDP 能够支持容忍数据包丢失的带宽密集型应用程序
  - UDP 具有低延迟的特点
  - UDP 能够发送大量的数据包
  - UDP 能够允许 DNS 查找，DNS 是建立在 UDP 之上的应用层协议。

### 15.2 TCP 是什么

- TCP 的全称是`Transmission Control Protocol` ，传输控制协议。它能够帮助你确定计算机连接到 Internet 以及它们之间的数据传输。通过三次握手来建立 TCP 连接，三次握手就是用来启动和确认 TCP 连接的过程。一旦连接建立后，就可以发送数据了，当数据传输完成后，会通过关闭虚拟电路来断开连接。
- TCP 的主要特点有
  - TCP 能够确保连接的建立和数据包的发送
  - TCP 支持错误重传机制
  - TCP 支持拥塞控制，能够在网络拥堵的情况下延迟发送
  - TCP 能够提供错误校验和，甄别有害的数据包。

### 15.3 TCP 和 UDP 的不同

![HTTP_8](/Users/na/IdeaProjects/Technical summary/Image/HTTP_8.png)

### 15.4 TCP 三次握手：TCP 的连接过程

![HTTP_9](/Users/na/IdeaProjects/Technical summary/Image/HTTP_9.png)

- SYN：它的全称是 `Synchronize Sequence Numbers`，同步序列编号。是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立 TCP 连接时，首先会发送的一个信号。客户端在接受到 SYN 消息时，就会在自己的段内生成一个随机值 X。
- SYN-ACK：服务器收到 SYN 后，打开客户端连接，发送一个 SYN-ACK 作为答复。确认号设置为比接收到的序列号多一个，即 X + 1，服务器为数据包选择的序列号是另一个随机数 Y。
- ACK：`Acknowledge character`, 确认字符，表示发来的数据已确认接收无误。最后，客户端将 ACK 发送给服务器。序列号被设置为所接收的确认值即 Y + 1。

![HTTP_10](/Users/na/IdeaProjects/Technical summary/Image/HTTP_10.webp)

#### 15.4.1 tcp 为什么要三次握手，两次不行吗

- 为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误。
- **具体例子：**“已失效的连接请求报文段”的产生在这样一种情况下：client发出的第一个连接请求报文段并没有丢失，而是在某个网络结点长时间的滞留了，以致延误到连接释放以后的某个时间才到达server。本来这是一个早已失效的报文段。但server收到此失效的连接请求报文段后，就误认为是client再次发出的一个新的连接请求。于是就向client发出确认报文段，同意建立连接。假设不采用“三次握手”，那么只要server发出确认，新的连接就建立了。由于现在client并没有发出建立连接的请求，因此不会理睬server的确认，也不会向server发送数据。但server却以为新的运输连接已经建立，并一直等待client发来数据。这样，server的很多资源就白白浪费掉了。采用“三次握手”的办法可以防止上述现象发生。例如刚才那种情况，client不会向server的确认发出确认。server由于收不到确认，就知道client并没有要求建立连接。”

#### 15.4.2 序列号是随机的吗

- TCP在开始传输数据前，客户端和服务器需要随机生成自己的初始序列号。C假冒A，B接受后把ACK会直接发给A。由于A没有发送过seq=ISN _C的请求，当A收到ISN_C的ack后直接发送reset 给B，最终关闭了链接。
- **加入初始序列号不是随机的，而是可以推测的，那么C就可以拿到ISN_B，然后模拟一个ACK过去，B最终会建立链接，**C开始传递数据，这就会产生非常严重的安全问题，所以ISN随机是必须的。

### 15.5 TCP 四次挥手：TCP 的释放过程

- 首先，客户端应用程序决定要终止连接(这里服务端也可以选择断开连接)。这会使客户端将 FIN 发送到服务器，并进入 `FIN_WAIT_1` 状态。当客户端处于 FIN_WAIT_1 状态时，它会等待来自服务器的 ACK 响应。
- 然后第二步，当服务器收到 FIN 消息时，服务器会立刻向客户端发送 ACK 确认消息。
- 当客户端收到服务器发送的 ACK 响应后，客户端就进入 `FIN_WAIT_2` 状态，然后等待来自服务器的 `FIN` 消息
- 服务器发送 ACK 确认消息后，一段时间（可以进行关闭后）会发送 FIN 消息给客户端，告知客户端可以进行关闭。
- 当客户端收到从服务端发送的 FIN 消息时，客户端就会由 FIN_WAIT_2 状态变为 `TIME_WAIT` 状态。处于 TIME_WAIT 状态的客户端允许重新发送 ACK 到服务器为了防止信息丢失。客户端在 TIME_WAIT 状态下花费的时间取决于它的实现，在等待一段时间后，连接关闭，客户端上所有的资源（包括端口号和缓冲区数据）都被释放。

![HTTP_11](/Users/na/IdeaProjects/Technical summary/Image/HTTP_11.png)

#### 15.5.1 四次挥手中什么是 time_wait 状态 ？

- TCP 连接中，**主动关闭连接**的一方出现的状态；（收到 FIN 命令，进入 TIME_WAIT 状态，并返回 ACK 命令）
- 为了保证 `ACK 重发`和`丢弃延迟数据`，设置 `time_wait` 为 2 倍的 `MSL`（报文最大存活时间）
- **可靠的实现 TCP 全双工连接的终止**：为了保证客户端发送的最后一个ACK报文能够到达服务端。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的服务端收不到对已发送的FIN+ACK报文段的确认。服务端会超时重传这个FIN+ACK报文段，而客户端就能在2MSL时间内收到这个重传的FIN+ACK报文段。如果客户端在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后就立即释放连接，就无法收到服务端重传的FIN+ACK报文段，因而也不会再发送一次确认报文段。这样，服务端就无法按照正常的步骤进入CLOSED状态。 
- **处理延迟到达的报文**：客户端在发送完ACK报文段后，再经过2MSL时间，就可以使本连接持续的时间所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求的报文段。假设客户端发送ACK刚刚过了一个MSL时间，而服务端在收到这个ACK**之前一瞬间刚好**启动超时重传FIN，所以要等这个FIN也消失，就是2MSL了。

#### 15.5.2  time_wait状态什么场景下过多，会造成什么问题？

- 在**高并发短连接**的TCP服务器上，当服务器处理完请求后立刻主动正常关闭连接。这个场景下会出现大量socket处于TIME_WAIT状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上。
- **高并发可以让服务器在短时间范围内同时占用大量端口**，而端口有个0~65535的范围，并不是很多，刨除系统和其他服务要用的，剩下的就更少了。
-  在这个场景中，**短连接表示“业务处理+传输数据的时间 远远小于 TIMEWAIT超时的时间”的连接**。
-  在socket的TIME_WAIT状态结束之前，该socket所占用的本地端口号将一直无法释放。
- 在高并发（每秒几万qps）并且采用短连接方式进行交互的系统中运行一段时间后，系统中就会存在大量的time_wait状态，如果time_wait状态把系统所有可用端口都占完了且尚未被系统回收时，就会出现无法向服务端创建新的socket连接的情况。此时系统几乎停转，任何链接都不能建立。

#### 15.5.3  close_wait 状态?

- 服务器端接收到客户端发送的FIN并发送ACK后进入该状态，该状态下服务器端如果还有数据则继续发送，否则发送FIN进入LAST_ACK状态

#### 15.5.4  close_wait 状态什么场景下过多，会造成什么问题？

- CLOSE_WAIT 状态在服务器停留时间很短，如果你发现大量的 CLOSE_WAIT 状态，那么就意味着被动关闭的一方没有及时发出 FIN 包，一般有如下几种可能：
  1. **程序问题：如果代码层面忘记了 close 相应的 socket 连接**，那么自然不会发出 FIN 包，从而导致 CLOSE_WAIT 累积；或者代码不严谨，出现死循环之类的问题，导致即便后面写了 close 也永远执行不到。
  2. **响应太慢或者超时设置过小：如果连接双方不和谐，一方不耐烦直接 timeout，另一方却还在忙于耗时逻辑，就会导致 close 被延后**。响应太慢是首要问题，不过换个角度看，也可能是 timeout 设置过小。

#### 15.5 为什么要四次挥手

- TCP协议是一种面向连接的、可靠的、基于字节流的运输层通信协议。TCP是全双工模式，这就意味着，当主机1发出FIN报文段时，只是表示主机1已经没有数据要发送了，主机1告诉主机2，它的数据已经全部发送完毕了；但是，这个时候主机1还是可以接受来自主机2的数据；当主机2返回ACK报文段时，表示它已经知道主机1没有数据发送了，但是主机2还是可以发送数据到主机1的；当主机2也发送了FIN报文段时，这个时候就表示主机2也没有数据要发送了，就会告诉主机1，我也没有数据要发送了，之后彼此就会愉快的中断这次TCP连接。

## 16. 地址栏输入 URL 发生了什么

- 在地址栏中输入了 `URL`，而地址栏会根据用户输入，做出如下判断：
  - 输入的是非 `URL` 结构的字符串，则会用浏览器默认的搜索引擎搜索该字符串
  - 输入的是 `URL` 结构字符串，则会构建完整的 `URL` 结构，浏览器进程会将完整的 `URL` 通过进程间通信，即 `IPC`，发送给网络进程
- 在网络进程接收到 `URL` 后，并不是马上对指定 `URL` 进行请求。首先，我们需要进行 `DNS` 解析域名得到对应的 `IP`，然后通过 `ARP` 解析 `IP` 得到对应的 `MAC`（`Media Access Control Address`）地址。而 `DNS` 解析域名的过程分为以下几个步骤：
  - 询问浏览器 `DNS` 缓存
  - 询问本地操作系统 `DNS` 缓存（即查找本地 `host` 文件）
  - 询问 `ISP`（`Internet Service Provider`）互联网服务提供商（例如电信、移动）的 `DNS` 服务器
  - 询问根服务器，这个过程可以进行递归和迭代两种查找的方式，如果根域名服务器无法告知本地 DNS 服务器下一步需要访问哪个顶级域名服务器，就会使用递归查询；可以告知则使用迭代
- 建立 `TCP` 连接，即**三次握手过程**，利用 `TCP` 通道进行**数据传输**：
  - 服务端接收到数据包，并发送确认数据包已收到的消息到客户端，不断重复这个过程
  - 客户端在发送一个数据包后，未接收到服务端的确定消息，则重新发送该数据包，即 `TCP` 的重发机制
  - 当接收完所有的数据包后，接收端会按照 `TCP` 头中的需要进行排序，形成完整的数据
- 在数据传输的过程还可能会发生的重定向的情况，即当网络进程接收到状态码为 3xx 的响应报文，则会根据响应报文首部字段中的 Location 字段的值进行重新向，即会重新发起请求
- 用户输入网址后向服务器发送内容请求，服务器接收到请求后触发Controller（控制器），控制器从Model（模型）和视图（View）中获取各种数据信息进行处理，最后视图（View）将数据渲染为HTML使得页面完整的呈献给用户。

- 最后，断开 `TCP` 连接，即**四次握手过程**

## 17. Cookie Session Token jwt

### 17.1 Cookie

- 称之为**会话跟踪技术**，就是在一次会话中跟踪记录一些状态。cookie就可以在一次会话从开始到结束的整个过程，全程跟踪记录客户端的状态（例如：是否登录、购物车信息、是否已下载等）。
- **cookie 存储在客户端：** cookie 是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。
- **cookie 是不可跨域的：** 每个 cookie 都会绑定单一的域名，无法在别的域名下获取使用，**一级域名和二级域名之间是允许共享使用的**（**靠的是 domain）**。
- cookie是储存在浏览器中的一段字符串，它本身是没有任何危害的，不包含任何可执行的代码。
- 储存cookie是**浏览器的功能**，浏览器的安装目录下会有一个专门存放不同域名下的**cookie**的文件夹。
- 当网页发起**http请求**的时候，浏览器首先会检查是否有对应域名的**cookie**，如果有，就会自动添加到**request header**中，发送给服务器。
- cookie的存放有大小限制，不可以超过4kb, 每一个域名下的cookie数量最多是20个

#### 17.1.1 通讯流程

- 登录的时候，服务器会响应头会返回一个不同用户的一个标识符(**cookie**) 
- 登录完成后，**cookie**会被存放在浏览器的不同域名下的**cookie**的文件夹中
- 访问服务器时，**浏览器**会自动在请求头带上刚刚存放的cookie去请求服务器
- 服务器接收到对应的cookie后，返回不同用户的数据给浏览器

#### 17.1.2 cookie的参数

- **expires**和**maxAge**  cookie在什么时间段内有效，maxAge的使用更加的方便和普遍，因为`expires`的时间限制是格林威治时间，写起来不方便，`maxAge`是根据你的当前时间+ 设置的时间(毫秒)，更加的方便。
- **domain**和**path**  限制cookie能被那些网站访问
- **secure**  设置`cookie`只在确保安全的请求中才会发送(https等安全协议)
- **httpOnly**  设置cookie能否通过js来访问，拥有httpOnly的cookie只能被服务器访问，客户端/浏览器不能访问，可以用来防止XSS脚本攻击。黑客虽然无法直接读取（这里假设了浏览器支持httpOnly, 这个功能在主流浏览器中是普遍支持的,但是在相对旧的版本浏览器可能并不支持），但是黑客依然可以通过HTTP trace来获取服务器返回的Cookie内容。所以在服务器端你需要将trace禁用。

### 17.2 Session

- **session 是另一种记录服务器和客户端会话状态的机制**
- **session 是基于 cookie 实现的，session 存储在服务器端，sessionId 会被存储到客户端的cookie 中**
- **session 认证流程：**
  - 用户浏览器访问web网站，输入用户名密码
  - 服务器校验用户名密码通过之后，生成sessonid并把sessionid和用户信息映射起来保存在服务器
  - 服务器将生成的sessionid返回给用户浏览器，浏览器将sessionid存入cookie
  - 此后用户对该网站发起的其他请求都将带上cookie中保存的sessionid
  - 服务端把用户传过来的sessionid和保存在服务器的sessionid做对比，如果服务器中有该sessionid则代表身份验证成功
- 缺点：
  - 代码安全机制不完善，可能存在CSRF漏洞
  - 服务端需要保存sessionid与客户端传来的sessionid做对比，当服务器为集群多机的情况下，需要复制sessionid，在多台集群机器之间共享
  - 如果需要单点登入，则须将sessionid存入redis等外部存储保证每台机器每个系统都能访问到，如果外部存储服务宕机，则单点登入失效

### 17.4 **Token**

- **访问资源接口（API）时所需要的资源凭证**
- **简单 token 的组成：** uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign（签名，token 的前几位以哈希算法压缩成的一定长度的十六进制字符串）
- **特点：**
  - **服务端无状态化、可扩展性好**
  - **支持移动端设备**
  - 安全
  - 支持跨程序调用
- **token 的身份验证流程**：
  - 客户端使用用户名跟密码请求登录
  - 服务端收到请求，去验证用户名与密码
  - 验证成功后，服务端会签发一个 token 并把这个 token 发送给客户端
  - 客户端收到 token 以后，会把它存储起来，比如放在 cookie 里或者 localStorage 里
  - 客户端每次向服务端请求资源的时候需要带着服务端签发的 token
  - 服务端收到请求，然后去验证客户端请求里面带着的 token ，如果验证成功，就向客户端返回请求的数据

- **每一次请求都需要携带 token，需要把 token 放到 HTTP 的 Header 里**
- 基于 token 的用户认证是一种服务端无状态的认证方式，服务端不用存放 token 数据。用解析 token 的计算时间换取 session 的存储空间，从而减轻服务器的压力，减少频繁的查询数据库
- token 完全由应用管理，所以它可以避开同源策略

### 17.6 JWT

#### 17.6.1 token的结构

- 是一个很长的字符串，中间用点（`.`）分隔成三个部分

- Header 部分是一个 JSON 对象，描述 JWT 的元数据：
  - 签名的算法（alg）：默认是 HMAC SHA256（写成 HS256）
  - 令牌（token）的类型（type）：JWT 令牌统一写为`JWT`。
- Payload 部分也是一个 JSON 对象，用来存放实际需要传递的数据。
  - iss (issuer)：签发人
  - exp (expiration time)：过期时间
  - sub (subject)：主题
  - aud (audience)：受众
  - nbf (Not Before)：生效时间
  - iat (Issued At)：签发时间
  - jti (JWT ID)：编号
  - 私有字段
- Signature 部分是对前两部分的签名，防止数据篡改。
  
  - 首先，需要指定一个密钥（secret）。这个密钥只有服务器才知道，不能泄露给用户。然后，使用 Header 里面指定的签名算法（默认是 HMAC SHA256），按照下面的公式产生签名。
  
  - 服务器端进行验证时，使用相同的签名算法再次对头部和负载生成signature，比较token携带的signature和生成的是否一致，如果一致则合法
  
  - ```javascript
    HMACSHA256(
      base64UrlEncode(header) + "." +
      base64UrlEncode(payload),
      secret)
    ```

#### 17.6.2 JWT 认证流程

- 用户访问网站，输入账号密码登入
- 服务器校验通过，生成JWT，不保存JWT，直接返回给客户端
- 客户端将JWT存入cookie或者localStorage
- 此后用户发起的请求，都将使用js从cookie或者localStorage读取JWT放在http请求的header中，发给服务端
- 服务端获取header中的JWT，用base64URL算法解码各部分内容，并在服务端用同样的秘钥和算法生成signature，与传过来的signature对比，验证JWT是否合法

#### 17.6.3 签名算法
- **HS256**

  - HS256 数字签名基于一种特殊的函数：加密哈希函数SHA-256。
  - **哈希函数属性**
    - **不可逆性**：函数是完全不可逆的，把Header和Payload作用于这个函数后，没有人可以从函数输出的信息中取回Header和Payload的原始值。
    - **可重复生成**：哈希函数是可重复生成信息的，也就是如果我们输入同样的Header和Payload信息，每次得到的结果是完全一样的。这就意味着，给定输入组合和哈希输出值，我们总是可以校验该输出值(比如签名signature)的正确性，因为我们可以重新计算(我们有输入值的情况下)。
    - **没有冲突**：如果我们提供不同的输入值，总是得到不同的唯一的输出值。这就意味着我们将哈希函数作用于某个Payload和Header之后，总是得到相同的结果，其它输入值组合不会得到和这一样的结果，因此，哈希函数的不同输出值就代表了输入值的不同。
    - **不可预测性**：哈希函数的最后一个属性就是不可预测性，给定一个输出值，无法通过各种手段猜测到输入值。假设我们尝试从上面的输出值中找到生成它的Payload，我们只能猜测输入值然后对比输出值看看是否匹配。
  - 缺点：
    - 如果输入的密码相对弱的话，HS256可能会被暴力破解，基于密钥的技术都有这个问题。
    - 在修改密码后，需要把它分发并安装到所有需要它的网络节点。这不仅不方便，而且容易出错，还涉及到服务器间的协调和暂停服务问题。如果服务器是由另外的团队维护，比如第三方组织，这种方式就更不可行了。
    - 创建和校验JWT的能力没有区分开，使用HS256时，网络的任何人都可以创建和校验token，因为他们都有密码。这就意味着密码可能会从更多的地方丢失或者受攻击，因为密码到处分发，而并不是每个应用都具有一样的安全保护机制。

- **RS256**([**RS256**](https://www.zhihu.com/search?type=content&q=hs256))

  - 使用RS256我们同样需要生成一个MAC，其目的仍然是创建一个数字签名来证明一个JWT的有效性。只是在这种签名方式中就，我们将创建token和校验token的能力分开，只有认证服务器具备创建的能力，而应用服务器，具备校验的能力。

  - 这样，我们需要创建两个密钥而不是一个：

    1. 仍然需要一个私钥，不过这次它只能被认证服务器拥有，只用来签名JWT。
    2. 私钥只能用来签名JWT，不能用来校验它。
    3. 第二个密钥叫做公钥(public key)，是应用服务器使用来校验JWT。
    4. 公钥可以用来校验JWT，但不能用来给JWT签名。
    5. 公钥一般不需要严密保管，因为即便黑客拿到了，也无法使用它来伪造签名。

  - RS256使用一种特殊的密钥，叫RSA密钥。RSA是一种加解密算法，使用一个密钥进行加密，然后用另外一个密钥解密。值得注意的是，RSA不是哈希函数，从定义上来说，这种方式加密是可逆的，也就是我们可以从加密后的内容得到原始内容。

  - 接收者将:

    1. 取出Header和Payload，然后使用SHA-256进行哈希。
    2. 使用公钥解密数字签名，得到签名的哈希值。
    3. 接收者将解密签名得到的哈希值和刚使用Header和Payload参与计算的哈希值进行比较。如果两个哈希值相等，则证明JWT确实是由认证服务器创建的。

    任何人都可以计算哈希值，但只有认证服务器可以使用RSA私钥对其进行加密。

#### 17.6.4 CSRF和XSS问题

- 使用JWT验证，由于服务端不保存用户信息，不用做sessonid复制，这样集群水平扩展就变得容易了。同时用户发请求给服务端时，前端使用JS将JWT放在header中手动发送给服务端，服务端验证header中的JWT字段，而非cookie信息，这样就避免了CSRF漏洞攻击。

#### 17.6.5 JTW优缺点

- 优点：
  - 服务端无需存储jwt令牌，通过特定的算法和密钥校验token
  - 同时取出Payload中携带的用户ID，减少不必要的数据库查询
  - 使用JWT验证，由于服务端不保存用户信息，不用做sessonid复制，这样集群水平扩展就变得容易了。
  - 用户发请求给服务端时，前端使用JS将JWT放在header中手动发送给服务端，服务端验证header中的JWT字段，而非cookie信息，这样就避免了CSRF漏洞攻击。
- Spring的拦截器HandlerInterceptor接口，在Controller方法执行之前拦截需要鉴权的请求，验证token是否合法，合法就放行，不合法则直接抛出异常拦截请求。验证逻辑放在一个统一的切面层完成，Spring的AOP正好满足这一需要。
- jwt泄露，导致用户信息泄露，以及操作权被使用
1. jwt不能涉及用户关键数据，如果涉及需要将jwt进行加密。
  2. 缩短jwt有效期
  3. 使用https
  4. 重要服务进行二次验证
- jwt存储在哪？客户端能否统一处理让所有请求带上这个令牌？

  - 存储在cookie中,自动实现统一处理。但没法解决跨域问题
  - 设在http-header中，如 Authorization: Bearer <token> 。所有的http请求包含表单、ajax、同步跳转都要加上这个header.
- jwt伪造，如果签名密钥泄露出去了那么jwt就可以被伪造

  - 签名密钥泄露并且被伪造token，这个在服务端是无法感知的。只能加强对secret的管理，并且对重要服务进行二次校验。
- 怎么强制将某个jwt失效？无法做到类似踢出某个用户的动作
  - 使用JWT的方式就是存在这种问题、无法解决。因为数据都不存储在服务端。一旦颁发token只有等待失效。

### 17.7 CSRF（Cross-Site Request Forgery，跨站点伪造请求）

- 在一个浏览器中打开了两个标签页，其中一个页面通过窃取另一个页面的 cookie 来发送伪造的请求，因为 cookie 是随着请求自动发送到服务端的。
- 一个**CSRF**攻击需要2个条件
  1. **登录了一个受信任的网站A，并且本地存放了cookie**
  2. **在不关闭A的情况下，访问了危险网站B**
- 1. 第一，登录受害者网站。如果受害者网站是基于 cookie 的用户验证机制，那么当用户登录成功后，浏览器就会保存一份服务端的 SESSIONID。
2. 第二，这时候在同一个浏览器打开攻击者网站，虽然说它无法获取 SESSIONID 是什么（因为设置了 http only 的 cookie 是无法被 JavaScript 获取的），但是从浏览器向受害者网站发出的任何请求中，都会携带它的 cookie，无论是从哪个网站发出。
  3. 第三，利用这个原理，在攻击者网站发出一个请求，命令受害者网站进行一些敏感操作。由于此时发出的请求是处于 session 中的，所以只要该用户有权限，那么任何请求都会被执行。

![HTTP_28](/Users/na/IdeaProjects/Technical summary/Image/HTTP_28.webp)

- 服务器端防御CSRF攻击主要有三种策略：验证HTTP Referer字段，请求参数中添加csrf token并验证，在HTTP头中自定义属性并验证。
  - 验证HTTP Referer字段：根据HTTP协议，在HTTP头中有一个字段叫Referer，它记录了HTTP请求的来源地址。服务器端设置拦截器，验证Referer，如果是合法地址则通过。**Referer 是浏览器设置的，在浏览器兼容性大不相同的时代中，如果存在某种浏览器允许用户修改这个值，那么 CSRF 漏洞依然存在。**
  - 请求参数中添加csrf token并验证：由于CSRF的本质在于攻击者欺骗用户去访问自己设置的地址，所以如果要求在访问敏感数据请求时，要求用户浏览器提供不保存在cookie中，并且攻击者无法伪造的数据作为校验，那么攻击者就无法再执行CSRF攻击。这种数据通常是表单中的一个数据项。服务器将其生成并附加在表单中，其内容是一个伪乱数。当客户端通过表单提交请求时，这个伪乱数也一并提交上去以供校验。正常的访问时，客户端浏览器能够正确得到并传回这个伪乱数，而通过CSRF传来的欺骗性攻击中，攻击者无从事先得知这个伪乱数的值，服务器端就会因为校验token的值为空或者错误，拒绝这个可疑请求。
  - 在请求头中自定义属性并验证：自定义属性的方法也是使用token并进行验证，和前一种方法不同的是，这里并不是把token以参数的形式置于HTTP请求体中，而是把它放到HTTP请求头中自定义的属性里。将token放入请求头中的Authoriaztion字段中。这样解决了前一种方法在请求中加入token的不便，同时，通过这个类请求的地址不会被记录到浏览器的地址栏，也不用担心token会通过Referer泄露到其他网站。

### 17.8 xss(cross site scripting)跨网页脚本攻击

- 基本原理同sql注入攻击类似。页面上用来输入信息内容的输入框，被输入了可执行代码。
- 无论是cookie-session还是JWT，都存在被XSS攻击盗取的风险
- 避免xss攻击，客户端和服务端都应该对提交数据进行xss攻击转义。

### 17.9 Web Storage

- HTML5 提供了两种在客户端存储数据的新方法：localStorage和sessionStorage
- 优点：
  - CSRF免疫，因为不会被浏览器自动发送，后端并不需要花费时间精力来做CSRF相关的防护
  - 主要是用来作为本地存储来使用的，解决了cookie存储空间不足的问题(cookie中每条cookie的存储空间为4k)，localStorage中一般浏览器支持的是5M大小

#### 17.9.1 **localStorage**

- **localStorage**的生命周期是永久性的。localStorage存储的数据，即使关闭浏览器，也不会让数据消失，除非主动的去删除数据。

- 主要是用来作为本地存储来使用的，解决了cookie存储空间不足的问题(cookie中每条cookie的存储空间为4k)，localStorage中一般浏览器支持的是5M大小，这个在不同的浏览器中localStorage会有所不同。

- 局限：

  - 1、浏览器的大小不统一，并且在IE8以上的IE版本才支持localStorage这个属性

    2、目前所有的浏览器中都会把localStorage的值类型限定为string类型，这个在对我们日常比较常见的 JSON对象类型需要一些转换（JSON.parse（）//转为数组）（JSON.stringify() //转为字符串）

    3、localStorage在浏览器的隐私模式下面是不可读取的

    4、localStorage本质上是对字符串的读取，如果存储内容多的话会消耗内存空间，会导致页面变卡

    5、localStorage不能被爬虫抓取到

- localStorage与sessionStorage的唯一一点区别就是localStorage属于永久性存储，而sessionStorage属于当会话结束的时候，sessionStorage中的键值对会被清空

#### 17.9.2 **sessionStorage**

- **sessionStorage** 的生命周期是在浏览器关闭前。
- 特性：
  - 关闭浏览器sessionStorage 失效；
  - 页面刷新不会消除数据；
  - 只有在当前页面打开的链接，才可以访sessionStorage的数据，使用window.open打开页面和改变localtion.href方式都可以获 取到sessionStorage内部的数据;

## 18. Http1.0 和HTTP1.1 和 Http2.x 的区别

### 18.1 说说 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？

- HTTP/1.1 相比 HTTP/1.0 性能上的改进：
  - 使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。
  - 支持 管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。

## 18.2 那上面的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？

- HTTP/1.1 还是有性能瓶颈：

  - 请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 `Body` 的部分；
  - 发送冗长的首部。每次互相发送相同的首部造成的浪费较多；
  - 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞；
  - 没有请求优先级控制；
  - 请求只能从客户端开始，服务器只能被动响应。

- *1. 头部压缩*

  HTTP/2 会**压缩头**（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你**消除重复的分**。

  这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就**提高速度**了。

- *2. 二进制格式*

  HTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了**二进制格式。**

  头信息和数据体都是二进制，并且统称为帧（frame）：**头信息帧和数据帧**。
  
  因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这**增加了数据传输的效率**。
  
- *3. 数据流*

  HTTP/2 的数据包不是按顺序发送的，同一个连接里面连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

  每个请求或回应的所有数据包，称为一个数据流（`Stream`）。

  每个数据流都标记着一个独一无二的编号，其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数

  客户端还可以**指定数据流的优先级**。优先级高的请求，服务器就先响应该请求。

- *4. 多路复用*

  HTTP/2 是可以在**一个连接中并发多个请求或回应，而不用按照顺序一一对应**。

  移除了 HTTP/1.1 中的串行请求，不需要排队等待，也就不会再出现「队头阻塞」问题，**降低了延迟，大幅度提高了连接的利用率**。

  举例来说，在一个 TCP 连接里，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程非常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。

- *5. 服务器推送*

  HTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务不再是被动地响应，也可以**主动**向客户端发送消息。

  举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会用到的 JS、CSS 文件等静态资源主动发给客户端，**减少延时的等待**，也就是服务器推送（Server Push，也叫 Cache Push）。

## 18.3 HTTP/2 有哪些缺陷？HTTP/3 做了哪些优化？

- HTTP/2 主要的问题在于：多个 HTTP 请求在复用一个 TCP 连接，下层的 TCP 协议是不知道有多少个 HTTP 请求的。

  所以一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的**所有的 HTTP 请求都必须等待这个丢了的包被重传回来**。

  - HTTP/1.1 中的管道（ pipeline）传输中如果有一个请求阻塞了，那么队列后请求也统统被阻塞住了
  - HTTP/2 多请求复用一个TCP连接，一旦发生丢包，就会阻塞住所有的 HTTP 请求。

  这都是基于 TCP 传输层的问题，所以 **HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！**

- UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。

  大家都知道 UDP 是不可靠传输的，但基于 UDP 的 **QUIC 协议** 可以实现类似 TCP 的可靠性传输。

  - QUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，**其他流不会受到影响**。
  - TL3 升级成了最新的 `1.3` 版本，头部压缩算法也升级成了 `QPack`。
  - HTTPS 要建立一个连接，要花费 6 次交互，先是建立三次握手，然后是 `TLS/1.3` 的三次握手。QUIC 直接把以往的 TCP 和 `TLS/1.3` 的 6 次交互**合并成了 3 次，减少了交互次数**。

## 19. HTTP报文结构

### 19.1 HTTP请求报文

- 请求报文有4部分组成:
  - 请求行
  - 请求头
  - 空行
  - 请求体
  
- 请求行包括：请求方法、请求的URL的地址、HTTP协议版本。

- 请求头部: 报文头包含若干个属性，格式为“属性名:属性值”，服务端据此获取客户端的信息。
  
  - Client-IP：提供了运行客户端的机器的IP地址
  
    From：提供了客户端用户的E-mail地址
  
    **Host**：给出了接收请求的服务器的主机名和端口号
  
    Referer：提供了包含当前请求URI的文档的URL
  
    UA-Color：提供了与客户端显示器的显示颜色有关的信息
  
    UA-CPU：给出了客户端CPU的类型或制造商
  
    UA-OS：给出了运行在客户端机器上的操作系统名称及版本
  
    User-Agent：将发起请求的应用程序名称告知服务器
  
    **Accept**：告诉服务器能够发送哪些媒体类型
  
    Accept-Charset：告诉服务器能够发送哪些字符集
  
    Accept-Encoding：告诉服务器能够发送哪些编码方式
  
    Accept-Language：告诉服务器能够发送哪些语言
  
    TE：告诉服务器可以使用那些扩展传输编码
  
    Expect：允许客户端列出某请求所要求的服务器行为
  
    Range：如果服务器支持范围请求，就请求资源的指定范围
  
    **Cookie**：客户端用它向服务器传送数据
  
    Cookie2：用来说明请求端支持的cookie版本
  
- 请求体: post/put等请求携带的数据，键值对的形式

![HTTP_14](/Users/na/IdeaProjects/Technical summary/Image/HTTP_14.jpg)

### 19.2 HTTP响应报文

- 响应报文有4部分组成:
  - 响应行
  - 响应头
  - 空行
  - 响应体
- 响应行： 由协议版本，状态码和状态描述组成，例如`HTTP/1.1 200 OK`。
- 响应头：也是由多个属性组成
  - Age：(从最初创建开始)响应持续时间
  - Public：服务器为其资源支持的请求方法列表
  - Retry-After：如果资源不可用的话，在此日期或时间重试
  - Server：服务器应用程序软件的名称和版本
  - Title：对HTML文档来说，就是HTML文档的源端给出的标题
  - Warning：比原因短语更详细一些的警告报文
  - Accept-Ranges：对此资源来说，服务器可接受的范围类型
  - Vary：服务器会根据这些首部的内容挑选出最适合的资源版本发送给客户端
  - Proxy-Authenticate：来自代理的对客户端的质询列表
  - **Set-Cookie**：在客户端设置数据，以便服务器对客户端进行标识
  - Set-Cookie2：与Set-Cookie类似
  - WWW-Authenticate：来自服务器的对客户端的质询列表
- 响应体：服务器响应的数据

![HTTP_15](/Users/na/IdeaProjects/Technical summary/Image/HTTP_15.jpg)

### 19.3 实体标头

- 实体标头是描述消息正文内容的 HTTP 标头。实体标头用于 HTTP 请求和响应中。头部`Content-Length`、 `Content-Language`、 `Content-Encoding` 是实体头。

  - Content-Length 实体报头指示实体主体的大小，以字节为单位，发送到接收方。
  - Content-Language 实体报头描述了客户端或者服务端能够接受的语言。
  - Content-Encoding 这又是一个比较麻烦的属性，这个实体报头用来压缩媒体类型。Content-Encoding 指示对实体应用了何种编码。常见的内容编码有这几种： **gzip、compress、deflate、identity** ，这个属性可以应用在请求报文和响应报文中

  ![HTTP_16](/Users/na/IdeaProjects/Technical summary/Image/HTTP_16.webp)

### 19.4 请求标头

![HTTP_17](/Users/na/IdeaProjects/Technical summary/Image/HTTP_17.png)

### 19.5 响应标头

![HTTP_18](/Users/na/IdeaProjects/Technical summary/Image/HTTP_18.webp)

## 20. 让我们了解在HTTP/1.1有多少中请求方法

```java
1.GET为获取资源数据
get方法用于请求指定的页面信息，并返回请求消息的主体

2.POST为提交资源数据
post方法用于向指定的资源提交数据

3.PUT为更新资源数据
4.DELETE为删除资源数据
5.HEAD为读取资源的元数据
6.OPTIONS为读取资源多支持的所有请求方法
7.TRACE为回显服务器收到额请求
8.CONNECT为保留将来使用
```

## 21. TCP拥塞控制

- 拥塞控制（congestion control)是TCP协议的一项重要功能，TCP的拥塞控制机制是从端到端的角度，推测网络是否发生拥塞，如果推断网络发生拥塞，则立即将数据发送速率降下来，以便缓解网络拥塞。 

- TCP的拥塞控制采用的是窗口机制，通过调节窗口的大小实现对数据发送速率的调整。

- 发送端判断网络发生拥塞的依据是：发送端设置一个重传计时器RTO，对于某个已发出的数据报文段，如果在RTO计时到期后，还没有收到来自接收端的确认，则认为此时网络发生了拥塞。也就是**发生了超时重传，就会认为网络出现了用拥塞。**

- TCP的拥塞控制[算法]()包括了慢启动（slow start）、拥塞避免（congestion avoidance）、快速重传（fast retransmit）和快速恢复（fast recovery）四部分。

- **拥塞窗口** `cwnd`是发送方维护的一个 的状态变量，它会根据**网络的拥塞程度动态变化的**。swnd = min(cwnd, rwnd)，也就是拥塞窗口和接收窗口中的最小值。拥塞窗口 `cwnd` 变化的规则：

  - 只要网络中没有出现拥塞，`cwnd` 就会增大；
  - 但网络中出现了拥塞，`cwnd` 就减少；

- 慢启动：TCP采用试探的方法，逐渐增大拥塞窗口cwnd。通常在刚开始发送数据报文段时，先将拥塞窗口cwnd设置为一个TCP最大段长度MSS的值(1500-20-20=1460)。而在每收到一个数据报文段的确认后，cwnd就增加一个MSS的数值。如果定义从发送端发出一个数据报文段到收到这个数据报文段的确认的时间间隔为往返时间RTT，则在慢启动阶段，每经过一个RTT，cwnd的值就加倍。

- 慢启动门限  `ssthresh` （slow start threshold），`ssthresh` 的大小是 `65535` 字节。

  - 当 `cwnd < ssthresh` 时，使用慢启动算法。
  - 当 `cwnd >= ssthresh` 时，就会使用「拥塞避免算法」。

- 拥塞避免算法：当拥塞窗口 `cwnd` 「超过」慢启动门限 `ssthresh` 就会进入拥塞避免算法。它的规则是：**每当收到一个 ACK 时，cwnd 增加 1/cwnd。**拥塞避免算法就是将原本慢启动算法的指数增长变成了线性增长。

- 当发生了「超时重传」，则就会使用拥塞发生算法。这个时候，sshresh 和 cwnd 的值会发生变化：

  - `ssthresh` 设为 `cwnd/2`，
  - `cwnd` 重置为 `1`

- 快速重传：当接收方发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速地重传，不必等待超时再重传。

  TCP 认为这种情况不严重，因为大部分没丢，只丢了一小部分，则 `ssthresh` 和 `cwnd` 变化如下：

  - `cwnd = cwnd/2` ，也就是设置为原来的一半;
  - `ssthresh = cwnd`;
  - 进入快速恢复算法

- 快速恢复：快速重传和快速恢复算法一般同时使用，快速恢复算法是认为，你还能收到 3 个重复 ACK 说明网络也不那么糟糕，所以没有必要像 `RTO` 超时那么强烈。

  - 快速恢复算法如下：
  - 拥塞窗口 `cwnd = ssthresh + 3` （ 3 的意思是确认有 3 个数据包被收到了）
    - 重传丢失的数据包
    - 如果再收到重复的 ACK，那么 cwnd 增加 1
    - 如果收到新数据的 ACK 后，设置 cwnd 为 ssthresh，接着就进入了拥塞避免算法

![HTTP_24](/Users/na/IdeaProjects/Technical summary/Image/HTTP_24.webp)

## 22. TCP实现可靠性传输

- TCP 是通过序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输的。
- TCP 实现可靠传输的方式之一，是通过序列号与确认应答。在 TCP 中，当发送端的数据到达接收主机时，接收端主机会返回一个确认应答消息，表示已收到消息。

### 22.1 **重传机制**

- 常见的重传机制：
  - 超时重传
  - 快速重传
  - SACK
  - D-SACK
  
- 超时重传
  
  - 重传机制的其中一个方式，就是在发送数据时，设定一个定时器，当超过指定的时间后，没有收到对方的 `ACK` 确认应答报文，就会重发该数据
  - TCP 会在以下两种情况发生超时重传：
    - 数据包丢失
    - 确认应答丢失
  
  ![HTTP_19](/Users/na/IdeaProjects/Technical summary/Image/HTTP_19.webp)

  - `RTT`（Round-Trip Time 往返时延）：就是**数据从网络一端传送到另一端所需的时间**，也就是包的往返时间。
  
  - 超时重传时间是以 `RTO` （Retransmission Timeout 超时重传时间）表示。
  
    ![HTTP_20](/Users/na/IdeaProjects/Technical summary/Image/HTTP_20.webp)
  
  - 上图中有两种超时时间不同的情况：
  
    - 当超时时间 **RTO 较大**时，重发就慢，丢了老半天才重发，没有效率，性能差；
    - 当超时时间 **RTO 较小**时，会导致可能并没有丢就重发，于是重发的就快，会增加网络拥塞，导致更多的超时，更多的超时导致更多的重发。
  
  - 根据上述的两种情况，我们可以得知，**超时重传时间 RTO 的值应该略大于报文往返  RTT 的值**。
  
  - 估计往返时间，通常需要采样以下两个：
  
    - 需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个平滑 RTT 的值，而且这个值还是要不断变化的，因为网络状况不断地变化。
    - 除了采样 RTT，还要采样 RTT 的波动范围，这样就避免如果 RTT 有一个大的波动的话，很难被发现的情况。
  
  - 如果超时重发的数据，再次超时的时候，又需要重传的时候，TCP 的策略是**超时间隔加倍。**也就是**每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。**
  
- **快速重传（Fast Retransmit）**

  - **不以时间为驱动，而是以数据驱动重传**。
  
  - 快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。
  
    ![HTTP_21](/Users/na/IdeaProjects/Technical summary/Image/HTTP_21.png)
  
  - 在上图，发送方发出了 1，2，3，4，5 份数据：
  
    - 第一份 Seq1 先送到了，于是就 Ack 回 2；
    - 结果 Seq2 因为某些原因没收到，Seq3 到达了，于是还是 Ack 回 2；
    - 后面的 Seq4 和 Seq5 都到了，但还是 Ack 回 2，因为 Seq2 还是没有收到；
    - **发送端收到了三个 Ack = 2 的确认，知道了 Seq2 还没有收到，就会在定时器过期之前，重传丢失的 Seq2。**
    - 最后，接收到收到了 Seq2，此时因为 Seq3，Seq4，Seq5 都收到了，于是 Ack 回 6 。
  
  - 快速重传机制只解决了一个问题，就是超时时间的问题，但是它依然面临着另外一个问题。就是**重传的时候，是重传之前的一个，还是重传所有的问题。**
  
- `SACK`（ Selective Acknowledgment 选择性确认）

  - 这种方式需要在 TCP 头部「选项」字段里加一个 `SACK` 的东西，它**可以将缓存的地图发送给发送方**，这样发送方就可以知道哪些数据收到了，哪些数据没收到，知道了这些信息，就可以**只重传丢失的数据**。
  
  - 如下图，发送方收到了三次同样的 ACK 确认报文，于是就会触发快速重发机制，通过 `SACK` 信息发现只有 `200~299` 这段数据丢失，则重发时，就只选择了这个 TCP 段进行重复。
  
    ![HTTP_22](/Users/na/IdeaProjects/Technical summary/Image/HTTP_22.webp)
  
- Duplicate SACK

  -  又称 `D-SACK`，其主要**使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。**
  
    ![HTTP_22](/Users/na/IdeaProjects/Technical summary/Image/HTTP_22.png)
  
  - ACK丢包：
  
    - 「接收方」发给「发送方」的两个 ACK 确认应答都丢失了，所以发送方超时后，重传第一个数据包（3000 ~ 3499）
    - **于是「接收方」发现数据是重复收到的，于是回了一个 SACK = 3000~3500**，告诉「发送方」 3000~3500 的数据早已被接收了，因为 ACK 都到了 4000 了，已经意味着 4000 之前的所有数据都已收到，所以这个 SACK 就代表着 `D-SACK`。
    - 这样「发送方」就知道了，数据没有丢，是「接收方」的 ACK 确认报文丢了。
    
    ![HTTP_23](/Users/na/IdeaProjects/Technical summary/Image/HTTP_23.png)
    
  -  网络延迟：
  
    -   数据包（1000~1499） 被网络延迟了，导致「发送方」没有收到 Ack 1500 的确认报文。
    -   而后面报文到达的三个相同的 ACK 确认报文，就触发了快速重传机制，但是在重传后，被延迟的数据包（1000~1499）又到了「接收方」；
    -   **所以「接收方」回了一个 SACK=1000~1500，因为 ACK 已经到了 3000，所以这个 SACK 是 D-SACK，表示收到了重复的包。**
    -   这样发送方就知道快速重传触发的原因不是发出去的包丢了，也不是因为回应的 ACK 包丢了，而是因为网络延迟了。
    
  -  可见，`D-SACK` 有这么几个好处：
  
     1. 可以让「发送方」知道，是发出去的包丢了，还是接收方回应的 ACK 包丢了;
     2. 可以知道是不是「发送方」的数据包被网络延迟了;
     3. 可以知道网络中是不是把「发送方」的数据包给复制了;

### 22.2 滑动窗口

- 窗口大小就是指**无需等待确认应答，而可以继续发送数据的最大值**。
- 窗口的实现实际上是操作系统开辟的一个缓存空间，发送方主机在等到确认应答返回之前，必须在缓冲区中保留已发送的数据。如果按期收到确认应答，此时数据就可以从缓存区清除。
- TCP 头里有一个字段叫 `Window`，也就是窗口大小。**这个字段是接收端告诉发送端自己还有多少缓冲区可以接收数据。于是发送端就可以根据这个接收端的处理能力来发送数据，而不会导致接收端处理不过来。**

## 23. TCP每个数据包大小怎么决定的，怎么计算的

- 以太网数据包（packet）的大小是固定的，最初是1518字节，后来增加到1522字节。其中， 1500 字节是负载（payload），22字节是头信息（head）。
- IP 数据包在以太网数据包里面，TCP 数据包在 IP 数据包里面。

![HTTP_26](/Users/na/IdeaProjects/Technical summary/Image/HTTP_26.png)

- TCP 包的大小就应该是 1522 - 以太网头(22) - IP头(20) - TCP头(20) = 1460 (BYTES)
- UDP 包的大小就应该是1522 - 以太网头(22) - IP头(20) - UDP头(8) = 1472(BYTES)

## 24. HTTP 连接建立过程

- 第1步：TCP通过三次握手建立双方连接；
- 第2步：客户端通过发送请求报文及请求数据给服务端；
- 第3步：服务端返回响应报文及响应数据给客户端；
- 第4步：TCP通过四次挥手进行断开连接。

![HTTP_25](/Users/na/IdeaProjects/Technical summary/Image/HTTP_25.png)

## 25. TCP如何保证传输的可靠性

1. 数据包校验
2. 对失序数据包重新排序（TCP报文具有序列号）
3. 丢弃重复数据
4. 应答机制：接收方收到数据之后，会发送一个确认（通常延迟几分之一秒）；
5. 超时重发：发送方发出数据之后，启动一个定时器，超时未收到接收方的确认，则重新发送这个数据；
6. 流量控制：确保接收端能够接收发送方的数据而不会缓冲区溢出，**使用滑动窗口协议实现流量控制**。防止发送方发送速率太快，接收方缓存区不够导致溢出。接收方会维护一个接收窗口 receiver window（窗口大小单位是字节），接受窗口的大小是根据自己的资源情况动态调整的，在**返回ACK时将接受窗口大小放在TCP报文中的窗口字段**告知发送方。发送窗口的大小不能超过接受窗口的大小，**只有当发送方发送并收到确认之后，才能将发送窗口右移**。